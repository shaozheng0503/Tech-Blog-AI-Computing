# 少步数图像生成模型对比：LCM、SDXL Turbo 与 SDXL Lightning 该如何选择？

> **核心摘要**
>
> 像 LCM、SDXL Turbo 和 SDXL Lightning 这类少步数（few-step）图像生成模型，是目前在几秒钟内产出高质量图像的顶尖技术。其中，LCM 能在不到一秒的时间里生成图像，但质量可能不及后两者；SDXL Turbo 致力于平衡速度与细节；而 SDXL Lightning 则在追求极致速度的同时，尽力不牺牲图像质量。

少步数图像生成模型仅需 1-8 次迭代就能生成一张图片（而标准模型大约需要 50 次），这使得它们比前辈们更快、计算效率也更高。这些模型优化技术主要有三个目标：

1.  **追求速度**（实现实时或近乎实时的生成）。
2.  **提升吞吐量**（即计算资源上每秒能生成的图像数量）。
3.  **保持（甚至提升）** 图像的细节和分辨率。

在这篇指南中，我们将剖析基于扩散的图像生成技术存在的瓶颈，比较当前最先进的几款少步数图像生成模型，讨论它们的局限性，并解释如何为你的应用场景选择最合适的那一个。

## 图像生成模型的演进之路

图像生成并非一开始就依赖深度学习，但我们今天看到的现代 AI 生成图像，正是深度学习融入该领域的结果。特别是 2014 年**生成对抗网络（GANs）**的发表，标志着一个转折点，它是最早能生成逼真图像的模型之一。到了 2015 年，**alignDRAW** 利用迭代生成过程，成为了第一个文生图（text-to-image）模型。

近年来，基于**扩散（Diffusion）**的方法主导了这一领域。像 Stable Diffusion、DALL-E 3 和 Imagen 等模型，极大地提升了图像的质量（细节、真实感、多样性）和分辨率（最高可达 1024x1024 像素）。尽管推理速度也有所提升，但这至今仍是一个悬而未决的重大问题：**如何在不牺牲质量的前提下，进一步提升速度？**

扩散模型通过从随机噪声开始，通过迭代步骤逐步将其转换为图像。由于这种迭代式的生成方式，扩散模型一直难以达到实时的生产速度。一个预训练好的 Stable Diffusion 模型需要多达 50 个步骤才能在推理时生成一张细节丰富的图像。对于 SDXL，即便是在 A100 这样的顶级硬件上进行优化部署，也需要超过 3 秒的时间。

为了解决这个问题，业界开发出了三种先进的方法，将迭代次数锐减到仅需 1-8 步，从而加速图像生成。它们分别是：

*   **潜在一致性模型（Latent Consistency Models, LCMs）**
*   **Stable Diffusion XL Turbo（SDXL Turbo）**
*   **Stable Diffusion XL Lightning（SDXL Lightning）**

## 潜在一致性模型 (LCMs)

潜在一致性模型（LCMs）经过特殊训练，能够直接预测目标图像的隐空间向量，从而跳过了扩散过程中漫长的迭代步骤。理论上，这意味着 LCMs 仅需一步就能预测出图像；但在实践中，这个过程通常会重复 2-4 次，以获得更好的图像质量。

训练一个 LCM 的步骤如下：

1.  从一个加噪序列中采样两个不同噪声水平的隐空间图像向量。
2.  对这两个样本分别预测其对应的"无噪声"目标图像向量。
3.  通过优化，使两个预测结果之间的差异最小化。

![一系列企鹅图片，展示了不同程度的噪声，以及其中两张图对应的无噪声预测结果](https://www.baseten.co/blog/assets/lcm.png)

在高分辨率图像生成方面，LCMs 实现了质量与效率的强大结合。它们可以在自定义数据集上进行微调，并能生成多样化、细节丰富的 1024x1024 像素图像。**LCM-LoRA** 的出现，还引入了低秩适应（Low-Rank Adaption）训练方法，使得我们能更高效地学习 LCM 模块。

对于追求实时图像生成的场景，LCMs 是一个不错的选择。例如，**PixArt-𝝳** 模型能用半秒钟从文本提示生成 1024x1024 像素的图像。然而，这些图像的细节可能不如 SDXL Turbo 和 Lightning 生成的丰富。如果迭代次数过少（通常少于 4 次），图像也可能出现模糊或明显的伪影。

## Stable Diffusion XL Turbo (SDXL Turbo)

SDXL Turbo 和 SDXL Lightning 都运用了**蒸馏（distillation）**技术，旨在用更少的步骤复现传统 SDXL 的强大效果。SDXL Turbo 特别采用了一种名为**对抗性扩散蒸馏（Adversarial Diffusion Distillation, ADD）**的方法，该方法涉及三个模型：

1.  一个用预训练权重初始化的、相对简单的"**学生网络**"。
2.  一个更复杂的、预训练好的"**教师网络**"（通常是像 SDXL 这样的标准扩散模型）。
3.  一个**判别器模型**。

学生模型的学习目标有两个：

1.  匹配其教师（SDXL）的预测结果。
2.  欺骗判别器模型，因为判别器被训练用来区分"AI生成的样本"和"真实图像"。

这种方法之所以是"对抗性的"，是因为引入了判别器模型；而"蒸馏"则指的是训练简单模型去模仿复杂模型行为的技术。对抗性目标有助于提升图像质量，而蒸馏技术则让模型能在极少的迭代次数内达成目标。

SDXL Turbo 致力于在速度和质量之间取得平衡，仅需 1-4 步即可生成图像。与 LCMs 相比，在相近的生成时间下（在 A100 或 H100 上不到 1 秒），SDXL Turbo 旨在产出细节和保真度都更高的结果。但与 SDXL Lightning 和 LCMs 相比，Turbo 的一个缺点是它被设计为仅能生成 512x512 像素的图像。

## Stable Diffusion XL Lightning (SDXL Lightning)

SDXL Lightning 专为实现高推理速度和低响应延迟而优化。它在 SDXL Turbo 的基础上更进一步，最少仅需一步就能完成文生图（尽管在实践中通常需要 2-8 步来确保图像质量）。

与 SDXL Turbo 类似，SDXL Lightning 也使用对抗性蒸馏来保持图像质量。但不同的是，SDXL Lightning 还运用了**渐进式蒸馏（progressive distillation）**技术。该技术涉及训练一系列规模递减的模型，每个小模型都从前一个更大模型蒸馏出的知识中学习。渐进式蒸馏是 SDXL Lightning 能够显著提升速度和资源效率的关键。

在实际使用中，用户普遍认为 SDXL Lightning 生成的图像质量远超 SDXL Turbo。此外，SDXL Lightning 还能生成 1024x1024 像素的图像，支持不同的宽高比，并提供了能产出高质量输出的 LoRA 模型。

下面是一个例子，对比了 SDXL Lightning 和 SDXL Turbo 在处理相同提示（"a rhino wearing a suit"，"一只穿着西装的犀牛"）时的表现。SDXL Lightning 生成的图像在细节上要丰富得多。

![SDXL Lightning 和 SDXL Turbo 生成的"穿西装的犀牛"图像对比](https://www.baseten.co/blog/assets/sdxl-lightning-vs-turbo.png)

## 如何在三者之间做出选择？

这三种模型优化技术的共同目标都是：**绕过传统扩散模型中耗时的 UNet 降噪步骤**。

你的选择取决于你的核心需求：

*   **如果你最看重速度**：像 PixArt-𝝳 这样的 LCMs 能提供实时的图像生成体验，并且可以被适配到各种模型和任务中。但它们的图像质量可能无法达到 SDXL Turbo 或 Lightning 的水平。而 **SDXL Lightning** 在提供与 PixArt-𝝳 相当的推理速度的同时，图像质量通常更胜一筹。

*   **如果图像质量是你的首要考虑**：并且 512x512 像素的分辨率足够用，同时你愿意在推理时多等一两秒，那么 **SDXL Turbo** 是一个公允的选择。它在速度和保真度之间取得了很好的平衡。

*   **对于大多数通用场景**：许多用户发现 **SDXL Lightning** 生成的图像质量远优于 Turbo。考虑到 Lightning 不仅能生成高质量的 1024x1024 图像，支持不同宽高比，拥有丰富的 LoRA 生态，并且本身就为速度和效率做了深度优化，它无疑是大多数应用场景下的可靠选择。

如今，这些高效的图像生成模型已经可以在各大云算力平台上找到，你可以轻松地将它们部署到自己的服务中，为你的产品带来更具创造力和实时性的AI能力。

---
> **原文信息**
>
> 本文翻译并本地化改编自 Baseten 博客，以更贴合中文开发者的阅读习惯。
>
> *   **原作者**: Rachel Rapp
> *   **原文链接**: [Comparing few-step image generation models](https://www.baseten.co/blog/comparing-few-step-image-generation-models) 