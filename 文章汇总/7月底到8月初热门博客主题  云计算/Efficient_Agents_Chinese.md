# 高效智能体：在保持效果的同时降低成本的智能体构建方法

*OPPO AI 智能体团队*  
*2025年8月6日*

## 摘要

大语言模型驱动的智能体所具有的卓越能力使得复杂系统能够处理复杂的多步骤任务，但其不断上升的成本威胁着可扩展性和可访问性。本研究首次系统性地研究了现代智能体系统中效率与效果之间的权衡，解决了在不牺牲性能的前提下设计成本效益型系统的关键需求。

我们研究了三个关键问题：
1. 智能体任务本质上需要多少复杂性？
2. 何时额外的模块会产生收益递减？
3. 通过设计高效智能体框架可以获得多少效率提升？

通过在 GAIA 基准测试上的实证分析，我们评估了 LLM 骨干网络选择、智能体框架设计和测试时扩展策略的影响。使用成本通过率指标，我们量化了这些维度的效率-性能权衡。我们的发现为开发 **高效智能体** 提供了指导，这是一个具有任务需求最优复杂性的新型智能体框架。

**高效智能体** 保持了领先的开源智能体框架 OWL 96.7% 的性能，同时将运营成本从 $0.398 降低到 $0.228，在成本通过率方面实现了 28.4% 的改进。我们的工作为设计高效、高性能的智能体系统提供了可操作的见解，推动了 AI 驱动解决方案的可访问性和可持续性。

**联系方式：** 周王春树 zhouwangchunshu@oppo.com；朱赫 zhuhe@oppo.com  
**代码：** https://github.com/OPPO-PersonalAI/OAgents

## 1. 引言

大语言模型的推理和创造能力不断增强，为实际应用开辟了广阔的前景。研究人员开发了众多 LLM 驱动的智能体系统，并创建了大量能够处理复杂多步骤任务的令人着迷的产品。然而，这种进展反映了 NLP 研究中的熟悉轨迹：从 BERT 到 ChatGPT，研究人员一直优先考虑扩大模型规模以实现突破性能力，直到后来才转向优化效率、成本和环境影响。

我们认为智能体研究现在已经达到了类似的转折点。虽然越来越复杂的智能体架构可以解决非常复杂的问题，但它们的成本呈指数级增长。行业部署 starkly 揭示了这种紧张关系：尖端智能体产品（如 DeepResearch、Manus）展示了令人印象深刻的能力，但由于爆炸性的 LLM 调用开销而遭受高昂的运营成本。一些系统每个任务需要数百次 API 调用，尽管技术卓越，但在经济上不可持续。

我们的工作首次系统性地研究了现代智能体系统中效率与效果之间的权衡。通过严格的实证分析，我们研究了 3 个研究问题：

1. **智能体任务真正需要多少复杂性？**
2. **何时额外的模块会产生收益递减？**
3. **通过设计任务自适应智能体框架可以获得多少效率？**

通过剖析框架中的这些关系，我们为研究人员和实践者提供了可操作的见解。

## 2. 预备知识

### 2.1 设置

许多因素都会影响智能体系统的有效性和效率。在本文中，我们旨在从智能体系统的角度进行全面分析。这些因素不仅包括骨干 LLM 本身，还包括围绕它构建的智能体框架，包括：

- **规划机制**
- **工具使用**
- **记忆模块**
- **测试时扩展策略**

我们在 GAIA 上评估这些组件，这是一个流行且具有挑战性的智能体基准测试，通常需要智能体执行复杂推理来解决问题。

### 2.2 指标

理想的智能体应该同时实现高性能和计算效率。因此，除了通过 pass@1（一次尝试解决问题）来衡量准确性的有效性外，我们还使用 LLM 消耗的 token 数量和相关成本来评估效率。

我们采用**成本通过率指标**来量化模型效率。成本通过率指标，表示为 v(m,p)，表示使用模型 m 为问题 p 生成正确解决方案的预期货币成本。计算公式为：

```
v(m,p) = C_m(p) / R_m(p)
```

其中：
- C_m(p) 是单次推理尝试的成本
- R_m(p) 是成功率

## 3. 智能体系统效率-性能权衡分析

### 3.1 骨干网络

当前的大语言模型通过强化学习获得系统 2 推理能力，利用通常跨越数千个 token 或更多的扩展思维链过程。虽然这种方法显著增强了推理性能，但也大幅增加了计算成本，甚至导致过度思考的现象。

**关键发现：**

- **Claude 3.7 Sonnet** 在 GAIA 基准测试上实现了最高准确率（总体 61.82%），相比 GPT-4.1（53.33%），但其成本通过率显著更高（3.54 vs. 0.98）
- **稀疏模型**如 Qwen3-30B-A3B 表现出卓越的效率，尽管准确率适中（总体 17.58%），但成本通过率很低（总体 0.13）
- 随着任务难度从第 1 级增加到第 3 级，大型推理模型的成本通过率急剧上升

### 3.2 测试时扩展策略

测试时扩展通过利用多次推理运行来增强模型性能，但这些方法通常需要模型执行 N 次，显著增加 token 消耗。

**Best-of-N 结果：**
- 将 N 从 1 增加到 4 导致 token 消耗大幅增加（从 243k 到 325k）
- 性能改进微乎其微，准确率仅从 53.33% 略微增加到 53.94%
- 成本通过率从 0.98 上升到 1.28

### 3.3 规划

为了增强智能体处理长期任务的能力，通常在执行前采用规划模块。规划可以被视为连续的任务分解过程。

**关键见解：**
- 在特定范围内增加最大步骤数显著提高性能
- 当最大步骤从 4 增加到 8 时，准确率从 58.49% 上升到 69.81%
- 超过某个阈值后，进一步增加步骤不会增强性能，但会继续增加成本

### 3.4 工具使用

集成外部工具显著增强了智能体的能力，特别是在神经网络单独不足的场景中。我们专注于网络浏览器使用，因为它代表了广泛采用的多用途工具。

**工具配置影响：**
- 增加搜索源数量显著提高有效性和效率
- 简单的浏览器操作在有效性和效率方面都优于高级操作
- 扩展重新表述查询的数量持续改善有效性和效率

### 3.5 记忆

记忆是 LLM 驱动智能体系统的关键组件，使智能体能够与动态环境有效交互并从中学习。我们设计了六种记忆配置来评估其影响：

1. **简单记忆**：仅保留历史观察和行动
2. **总结记忆**：信息被总结和嵌入
3. **无额外记忆**：仅保留步骤历史
4. **额外总结记忆**：总结记忆与步骤历史一起
5. **额外固定记忆**：维护固定长度文本作为长期记忆
6. **额外混合记忆**：总结和长期记忆方法的结合

**结果：** 简单记忆配置产生最佳性能，从 53.33% 提高到 56.36%，同时将成本通过率从 0.98 降低到 0.74。

## 4. 高效智能体：技巧与策略

基于我们的实证研究，我们提出了**高效智能体**，这是一个由精心选择的组件组成的智能体系统，以实现效果和效率之间的良好权衡。

**配置策略：**
对于智能体系统中的每个组件，我们采用在不会导致性能显著下降的配置中成本通过率最低的配置。

**性能结果：**
- 实现 OWL 96.7% 的性能
- 降低运营成本 28.4%
- 成本通过率从 $0.398 改进到 $0.228

## 5. 相关工作

### 5.1 LLM 驱动的智能体

基于 LLM 的智能体技术在广泛的任务中展示了卓越的能力，显著推动了通用智能体系统的快速发展。最近的研究工作致力于构建能够处理复杂推理、规划和搜索任务的通用智能体系统。

**著名系统：**
- **OpenAI 的深度研究**：在 GAIA 基准测试上达到 67.36%
- **OWL（优化劳动力学习）**：在 GAIA 基准测试上得分 69.7%

### 5.2 高效 NLP

自 BERT 出现以来，语言模型的规模呈指数级增长，导致推理过程中的计算和能源成本大幅增加。大量研究专注于提高 NLP 效率。

**关键方法：**
- **知识蒸馏**：DistilBERT 从 BERT 创建紧凑模型
- **Token 预算感知**：通过估计 token 需求来控制模型输出长度
- **多智能体优化**：AgentPrune 通过修剪多余消息来优化通信

## 6. 结论

本文做出了几个关键贡献：

1. **全面分析**：我们提供了对当代智能体系统中导致经济开销的架构选择和操作因素的彻底分析。

2. **高效智能体框架**：我们引入了一个为任务性能和计算成本之间的最佳平衡而设计的新型智能体框架。

3. **实证验证**：我们在 GAIA 基准测试上的广泛实验证明了我们方法的有效性，实现了最先进性能的 96.7%，同时降低了 28.4% 的运营成本。

这项工作强调了在下一代智能体系统设计中效率考虑的关键重要性，并为更可扩展和经济可行的实际部署提供了实用途径。

## 核心贡献者

- 王宁宁
- 胡泽维

## 贡献者

- 刘派
- 侯月
- 黄鹤元
- 张胜宇
- 杨健
- 刘嘉恒
- 张戈
- 张长旺
- 王军
- 江雨晨

## 通讯作者

- 朱赫
- 周王春树

---

*本文档基于 OPPO AI 智能体团队的研究论文"高效智能体：在保持效果的同时降低成本的智能体构建方法"。更多信息请访问：https://github.com/OPPO-PersonalAI/OAgents* 