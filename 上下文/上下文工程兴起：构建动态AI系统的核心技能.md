# 2. "上下文工程"的兴起

*作者：LangChain 团队*  
*原文链接：https://blog.langchain.com/the-rise-of-context-engineering/*  
*阅读时间：5 分钟*

标题图片来自 Dex Horthy 在 Twitter 上的分享。

上下文工程（Context Engineering）是构建动态系统，以正确的格式提供正确的信息和工具，以便 LLM 能够合理地完成任务。

大多数情况下，当代理体无法可靠地执行时，根本原因是没有将适当的上下文、指令和工具传达给模型。

LLM 应用程序正在从单个提示演变为更复杂的动态代理系统。因此，上下文工程正在成为 AI 工程师可以培养的最重要的技能。

## 2.1 什么是上下文工程？

上下文工程是构建动态系统，以正确的格式提供正确的信息和工具，以便 LLM 能够合理地完成任务。

这是我喜欢的定义，它建立在 Tobi Lutke、Ankur Goyal 和 Walden Yan 最近对此的看法之上。让我们来分析一下。

### 2.1.1 上下文工程是一个系统

复杂代理可能从许多来源获取上下文。上下文可以来自应用程序的开发人员、用户、以前的交互、工具调用或其他外部数据。将所有这些整合在一起涉及一个复杂的系统。

### 2.1.2 这个系统是动态的

其中许多上下文可以动态地出现。因此，构建最终提示的逻辑也必须是动态的。它不仅仅是一个静态提示。

### 2.1.3 你需要正确的信息

代理系统不执行的一个常见原因是它们没有正确的上下文。LLM 不能读心术——你需要给它们正确的信息。垃圾进，垃圾出。

### 2.1.4 你需要正确的工具

LLM 可能并不总是能够仅根据输入来解决任务。在这些情况下，如果你想授权 LLM 执行此操作，则需要确保它具有正确的工具。这些可以是查找更多信息、采取行动或介于两者之间的任何工具。为 LLM 提供正确的工具与为其提供正确的信息一样重要。

### 2.1.5 格式很重要

就像与人类交流一样，你与 LLM 的交流方式也很重要。简短但描述性的错误消息将比大型 JSON blob 更进一步。这也适用于工具。在确保 LLM 可以使用工具的输入参数时，它们的输入参数非常重要。

### 2.1.6 它能合理地完成任务吗？

在考虑上下文工程时，这是一个很好的问题。它强调了 LLM 不是读心者——你需要为它们的成功做好准备。它还有助于区分故障模式。它失败是因为你没有给它正确的信息或工具吗？还是它拥有所有正确的信息，但只是搞砸了？这些故障模式的修复方法非常不同。

## 2.2 为什么上下文工程很重要

当代理系统搞砸时，主要是因为 LLM 搞砸了。从第一原则出发，LLM 可能会出错，原因有两个：

1. 底层模型只是搞砸了，它不够好
2. 底层模型没有传递适当的上下文来产生良好的输出

通常情况下（尤其是当模型变得更好时）模型错误更多地是由第二个原因引起的。传递给模型的上下文可能由于以下几个原因而损坏：

- 只是缺少模型做出正确决策所需的上下文。模型不是读心者。如果你不给它们正确的上下文，它们就不会知道它的存在。
- 上下文格式不佳。就像人类一样，沟通也很重要！传入模型时如何格式化数据绝对会影响它的响应方式。

## 2.3 上下文工程与提示工程有何不同？

为什么从"prompts"转向"context"？早期，开发人员专注于巧妙地措辞提示，以哄骗更好的答案。但随着应用程序变得越来越复杂，越来越明显的是，为 AI 提供完整和结构化的上下文比任何神奇的措辞都重要得多。

我还想说，提示工程是上下文工程的一个子集。即使你拥有所有的上下文，如何在 Prompt 中组合它仍然绝对重要。区别在于，你不是为了很好地处理一组输入数据来构建 prompt，而是采用一组动态数据并正确格式化它。

我还想强调的是，上下文的一个关键部分通常是 LLM 应该如何表现的核心指令。这通常是提示工程的关键部分。你认为为代理应该如何行为提供清晰详细的说明是上下文工程还是提示工程？我认为两者兼而有之。

## 2.4 上下文工程示例

良好的上下文工程的一些基本示例包括：

**工具使用**：确保如果代理需要访问外部信息，它有可以访问这些信息的工具。当工具返回信息时，它们会以 LLM 最容易理解的方式进行格式设置。

**短期记忆**：如果对话正在进行一段时间，请创建对话摘要并在将来使用它。

**长期记忆**：如果用户在之前的对话中表达了偏好，则能够获取该信息。

**提示工程**：提示中清楚地列举了代理应如何行为的说明。

**检索**：动态获取信息，并在调用 LLM 之前将其插入到提示符中。

## 2.5 LangGraph 如何实现上下文工程

当我们构建 LangGraph 时，我们构建它的目标是使其成为最可控的代理框架。这也使其能够完美地实现上下文工程。

使用 LangGraph，你可以控制一切。你可以决定运行哪些步骤。你决定你的 LLM 到底要做什么。你可以决定存储输出的位置。你控制一切。

这使你可以执行所需的所有上下文工程。代理抽象的缺点之一（大多数其他代理框架都强调）是它们限制了上下文工程。在某些地方，你无法准确更改进入 LLM 的内容，或者无法更改预先运行的步骤。

旁注：Dex Horthy 的《12 Factor Agents》是一本非常好的读物。其中的很多要点都与上下文工程有关（"拥有你的提示"、"拥有你的上下文构建"等）。此博客的标题图像也取自 Dex。我们真的很喜欢他传达空间中重要事物的方式。

## 2.6 LangSmith 如何帮助进行上下文工程

LangSmith 是我们的 LLM 应用程序可观察性和评估解决方案。LangSmith 的主要功能之一是能够跟踪你的代理调用。尽管在我们构建 LangSmith 时不存在"上下文工程"一词，但它恰如其分地描述了这种跟踪的帮助。

LangSmith 让你看到代理中发生的所有步骤。这样，你就可以查看运行了哪些步骤来收集发送到 LLM 的数据。

LangSmith 允许你查看 LLM 的确切输入和输出。这样，你就可以准确地看到 LLM 中的内容——它拥有的数据以及它是如何格式化的。然后，你可以调试它是否包含任务所需的所有相关信息。这包括 LLM 可以访问哪些工具——因此你可以调试是否为其提供了适当的工具来帮助完成手头的任务。

## 2.7 沟通就是你所需要的一切

几个月前，我写了一篇名为"沟通就是你所需要的一切"的博客。要点是与 LLM 沟通很困难，而且没有得到足够的重视，而且通常是许多代理错误的根本原因。其中许多要点都与上下文工程有关！

上下文工程并不是一个新想法——代理构建者在过去一两年里一直在这样做。这是一个新术语，恰如其分地描述了一项日益重要的技能。我们将撰写和分享有关此主题的更多信息。我们认为我们构建的许多工具（LangGraph、LangSmith）都是为实现上下文工程而构建的，因此我们很高兴看到人们对此的重视。

---

*原文作者：LangChain 团队*  
*翻译与本地化：面向中文 AI 开发者社区* 