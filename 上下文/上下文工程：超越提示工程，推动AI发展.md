# 1. 上下文工程：超越提示工程，推动 AI 发展

## 1.1 如何优化 AI 的"思考"内容

*作者：Dharmesh Shah*  
*原文链接：https://simple.ai/p/the-skill-that's-replacing-prompt-engineering*

如果你已经接触 AI 一段时间了，你就会遇到提示（prompt）的概念——这是你向 ChatGPT 等 LLM 发出指令的方式。

事实证明，你可以采取一些措施来更好地制作提示，以提高结果质量。这种技巧被称为"提示工程"（prompt engineering）——正如它听起来的那样，设计一个提示，让 LLM 做你想做的事。

但有趣的是：在过去两年中，随着上下文窗口从 4K 代币激增到超过 100 万代币，出现了比提示工程更强大的东西：上下文工程（context engineering）。（我想感谢我在 Shopify 的朋友 Tobi 创造了这个术语）

这种转变可能看起来很简单，但框架却完全不同——你现在不是优化你的提问方式，而是优化 AI 在思考时可以访问的内容。

因此，在今天的文章中，我将写一篇更具"指导性"的内容：

- 上下文窗口的工作原理及其重要性
- 从提示工程到上下文工程的演变
- 为什么这种转变对任何使用 AI 进行构建的人都很重要

## 1.2 什么是上下文窗口？

把它想象成你交给 LLM 的一张大纸。

你可以在上面写一定数量的字。这些词可以是"write me a limerick about pickleball"（给我写一首关于匹克球的打油诗）。或者，它们可以是"这是一篇 5000 字的文章，给我一个 100 字的总结"（你把整篇文章都写在那张大纸上）。

上下文窗口有一个限制，通常表示为多个"标记"（token）。一个标记大约是一个英语单词的 3/4 或大约 4 个字符。"ChatGPT"是两个代币："Chat"和"GPT"。这很重要，因为计费、延迟和内存都随令牌计数而扩展。

这是 LLM 的一个关键限制：它们只知道它们接受了什么训练，以及上下文窗口中提供给它们的是什么。

但是，随着上下文窗口在过去 2 年中令牌大小的爆炸式增长，我们在该上下文窗口中放置的内容变得越来越聪明，例如：

### 1.2.1 AI 如何"记住"你的对话

你可能已经注意到，ChatGPT 和 Claude 的短期记忆力很好。这就是为什么你可以提出后续问题，它们知道你在说什么。这是怎么发生的？在幕后，它们实际上是将你之前的提示和输出传递到上下文窗口中。这有点像电影《记忆碎片》，主角忘记了一切，不得不在身上写下笔记，这样他才能记住自己是谁和正在发生的事情（顺便说一句，这是一部很棒的电影）。

### 1.2.2 RAG：按需教授 AI

有一种称为 RAG（检索增强生成，Retrieval-Augmented Generation）的方法，我们可以找到一组与用户提示相关的文档，然后将这些文档传递到上下文窗口中（从而准确地"教"LLM 有助于回答问题或提示的内容）。

### 1.2.3 工具调用：扩展 AI 的功能

我们还引入了工具调用（tool calling）的概念。这是一种告诉 LLM 的方式："嘿，假装你可以使用这些工具集进行网络搜索、股票价格查询、天气预报等操作......随便什么。然后，LLM 可以使用提供的一个或多个工具（如果这些工具可以帮助它们处理提示）。

以下是关于工具调用工作原理的一个古怪但令人愉快的细节：当我们让 LLM 知道它有哪些可用的工具时，它实际上并没有调用工具本身。核心 LLM 不是为了做到这一点而构建的。它只是获取上下文并产生输出。我们告诉它可以访问哪些工具，以及输出，它让应用程序（如 ChatGPT）想要调用哪个工具。然后，应用程序代表 LLM 调用该工具，并将结果放在上下文窗口中并将其发送回去。这是解决 LLM 只与上下文窗口一起使用这一事实的聪明方法。

借助百万令牌上下文窗口，你可以向 AI 提供完整的代码库、完整的业务计划或数月的客户支持对话，并且它可以同时对所有这些信息进行推理。

## 1.3 为什么上下文工程很重要

还记得 2023 年的提示工程热潮吗？头条新闻在 Anthropic 等地方为"Prompt Engineers"推销 30 万美元以上的薪水。

很多工作都走红了，因为它们不需要正式的 CS 学位——只需要能说流利的"LLM"的能力。

虽然聘请了一些提示工程师，但最终并没有成为许多人预测的庞大工作类别。原因是什么？每个人都成为了一名提示工程师。现在，出现了更重要的东西：上下文工程。

上下文工程本质上是提示工程的更高级别版本。

一个（过于）简单的解释：提示工程就像学习提出非常好的问题。上下文工程就像一名图书管理员，在人们开始阅读之前就决定他们可以访问哪些书籍。

### 1.3.1 上下文工程师实际做什么

**策展**：确定哪些文档、记忆或 API 对每个特定任务很重要

**结构**：将系统消息→工具分层，→检索到的数据→以最佳顺序用户提示符

**压缩**：汇总或分块信息以保持在令牌限制范围内，同时保留重要内容

**评估**：测量准确性并注意"上下文稀释"，即不相关的信息会分散模型的注意力

请记住，更多的上下文意味着更丰富的文档和更长的对话。但成本和延迟大致随窗口长度线性增加。这为上下文工程师留下了大量空间来发现最佳实践（其中许多仍在兴起）。

上下文工程需要以提示工程从未有过的方式考虑信息架构、数据策略和用户体验。掌握这一点的公司将拥有巨大的竞争优势。

正如我想说的：提示告诉模型如何思考，但上下文工程为模型提供完成工作的训练和工具。

## 1.4 上下文优先的未来

2023 年的提示工程炒作教会了我们一个重要的教训：最有价值的 AI 技能不是学习秘密短语或聪明的技巧。

它们是关于了解如何构建能够在正确时间访问正确信息的智能系统。

这是从优化句子到优化知识的根本转变。这对于当今使用 AI 进行构建的任何人都很重要。

就我个人而言，作为与 agent.ai 一起在这个领域构建的人，我总是对当你不再将 AI 视为聊天机器人，开始将其视为具有正确上下文和工具的推理引擎时所发生的事情感到惊讶。

提示工程时代教会我们与 AI 对话。上下文工程时代正在教会我们用 AI 思考。

---

*原文作者：Dharmesh Shah，HubSpot 联合创始人兼首席技术官*  
*翻译与本地化：面向中文 AI 开发者社区* 