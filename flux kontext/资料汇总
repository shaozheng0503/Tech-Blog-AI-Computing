爆炸消息：Black Forest宣布开源对标GPT 4o的FLUX.1 Kontext 图像模型（内附教程 ）
Black Forest Labs 发布了 FLUX.1 Kontext [dev] 模型，这是其图像编辑模型 FLUX.1 Kontext [pro] 的开源开发版本，拥有 12B参数，具备 接近专有工具的图像编辑能力，并可在消费级硬件上运行。

其目标是提供一个性能接近闭源专有模型的免费工具。可在本地运行，无需联网，即可生成和编辑图像。

之前关于FLUX.1 Kontext [pro] 的介绍：实现GPT 4o图像生成编辑能力 BFL推出新一代多模态图像生成与编辑模型：FLUX.1 Kontext

这意味着大家可以摆脱GPT 4o和Gemini 模型根据聊天对话对图像编辑修改的垄断。

有很大的应用空间...

模型规模：12B 参数（对比 Stable Diffusion 约为 1B-2B）

模型定位：仅用于图像编辑（非从零生成），强调局部精准控制与角色一致性。

🔓 开源与可用性
模型在 FLUX.1 非商业许可下开源，支持研究与非商业用途。

由多个合作方（如 FAL、Replicate、Runware、DataCrunch、TogetherAI）提供云端或本地推理支持。

主要能力
FLUX.1 Kontext [dev]专注于 图像编辑任务：包括迭代编辑、角色保持、局部与全局精细控制。

可以非常准确地“重绘”图片中的局部或全图，比如：

把帽子加到人物头上

改变背景风景

把原图中的狗换成猫，人物保持原样

多次修改也不会“跑偏”或者失真

跟很多流行工具（如 ComfyUI）无缝结合，方便使用

图片

性能评估与对比

评估基准：使用其自研的 KontextBench（一个新的图像编辑评测集）

评估维度：

编辑精度（是否能实现用户期望的修改）

角色保持（人物面部/姿态的一致性）

多场景迁移（是否能适应复杂背景与构图）

对比模型：

开源模型：

Bytedance Bagel（文生图+编辑混合模型）

HiDream-E1-Full（开源扩散图像编辑模型）

闭源模型：

Google's Gemini-Flash Image

结果：Kontext [dev] 在多项任务中人类偏好得分优于上述所有模型，并由第三方机构 Artificial Analysis 独立验证。

图片

技术细节与优化

与 NVIDIA 合作，构建了专门针对全新 NVIDIA Blackwell 架构优化的 TensorRT 权重，该架构大幅提升推理速度并降低内存使用，同时保持高质量的图像编辑性能。

推理优化：

与 NVIDIA 合作，为最新的 Blackwell 架构（B100 GPU）定制推理优化：

提供 FP16、BF16、FP8、FP4 等低精度权重

极大降低延迟与显存需求，适配边缘设备部署

商业许可机制
推出自助购买平台（Self-Serve Portal）

支持在线获取商业授权，包括：

FLUX.1 Kontext [dev]

FLUX.1 Tools [dev]（辅助图像处理）

FLUX.1 [dev]（文本生成图像模型）

图片

模型下载：https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev

技术报告：https://arxiv.org/abs/2506.15742

ComfyUI 已经全面支持FLUX.1 Kontext [dev]

主要功能包括：

多步编辑：支持基于上下文的多轮图像修改；

角色一致性：可维持同一角色在不同画面中的一致性；

本地编辑：所有处理可在本地完成，无需云端；

风格参考：支持参照已有风格进行生成；

对象/背景移除：图像中可快速去除不需要的部分；

多图输入：支持多个输入图像；

文本编辑：允许对图像中的文本进行修改；

如何在 ComfyUI 使用
确保已更新 ComfyUI 或 ComfyUI 桌面版本。

路径：Workflow → Browse Templates → Flux → Flux.1 Kontext Dev

点击任意模板即可运行。

图片
提示词（Prompt）示例

以下是官方提供的提示语，展示其强大的图像理解与控制能力：

🎨 风格转换：

“Transform to 1960s pop art style with bright colors, bold graphics, and commercial aesthetics.”
转换为 1960 年代的波普艺术风格，色彩明亮、图形粗线条、商业美学。

图片
🔤 文字添加：

“Add ASCII style text only the single word 'In' no additional letters to the display.”
在图像中添加 ASCII 风格的 “In” 字母，不能包含其他字母。

图片
🔁 视角旋转：

“Rotate the camera 180 degrees to view directly from behind the dog, showing its back and tail while maintaining the same 3D style.”
将视角旋转 180 度，从狗的背后观察，展示尾巴，同时保留 3D 风格。

图片
移除物体



图片

图片

转换视角



图片



提示词示例： Rotate the camera 180 degrees to view directly from behind the dog, showing its back and tail while maintaining the same 3D style

（将相机旋转 180 度，直接从狗的背后进行拍摄，展示其背部和尾巴，同时保持相同的 3D 风格）



多轮编辑



图片


多图输入



图片

图片


风格迁移



图片


图片


改变光线



图片



提示词示例： Convert to early morning scene with soft golden sunrise light and gentle morning mist, maintaining the same composition and architectural details

（将场景转换为清晨场景，呈现柔和的金色日出光线和轻柔的晨雾，同时保持相同的构图和建筑细节）


更多使用技巧和教程详见：
🔗 https://docs.comfy.org/tutorials/flux/flux-1-kontext-dev



加入XiaoHu.ai 日报社群 每天获取最新的AI信息


图片
____________

End.

感 谢 阅 读

点赞，转发，关注关注关注！



图片





Kontext 开源，10 大玩法！这下可以彻底扔了 GPT-4o，卸载 PS 了
阿杰现在深耕 AI 视频/AI绘画，随时分享最新的 AI 技巧

点击 👇 关注阿杰，一起 AI 破局

刚得到好消息，Kontext 竟然开源了

图片
这下终于可以彻底抛弃 GPT-4o 了

官方已经发布了自己的模型，大家可以本地下载使用，当然阿杰更推荐大家直接用云端环境，开箱即用，省时省力。

今天给大家介绍一个仙宫云。

首先登录仙宫云，网址放在下面了

https://www.xiangongyun.com/

选择“部署 GPU”

图片
这里搜索“Kontext”，会看到很多镜像，随便选一个用就可以了

图片
点击右下角的“使用该镜像部署”，再选一个显卡，稍等片刻，这个镜像就部署好并且自动开机了

图片
图片
下面就是开机的界面，点击“ComfyUI”进入操作界面

图片
图片
进入操作界面之后，左侧有个蓝色的文件夹图标，打开就是各种工作流了。没有用过 ComfyUI 也没关系，把他当成一个黑盒子就行，我们只要上传图片

图片
再写个提示词就行

图片
下面给大家简单看几个 Kontext 的玩法吧


一、电商产品换背景
图片
将图中的产品放在一个石头上，周围都是花朵，有化妆品的广告氛围

图片
二、风格转绘
图片
Ghibli style

图片
三、风格迁移
图片
使用这种图像风格，一个女人在夜晚仰望星空，中景

图片
四、服装上身
图片
将图中的衣服穿在一个漂亮的亚洲女性模特身上

图片
五、换背景打光
图片
保持人物不变，背景改成夕阳下的傍晚海滩边

图片
六、局部编辑
图片
将男生的衣服变成一件粉色的毛衣

图片
七、老照片修复
图片
修复这张照片，去除裂痕，增强清晰度，校正色彩，将原始照片恢复到超高清画质。

图片
八、美甲
图片
将角色的指甲替换为不同颜色的艺术图案美甲

图片
九、角色一致性
图片
背景改成室内卧室，美女坐在床上看书

图片
十、修改文字
图片
将图片中的“ChatGPT”文字修改为“Everyone”,"GPT-4o"修改成"Kontext"

图片
最后，不用的话记得点击“销毁”彻底关闭镜像，不然会持续计费的哦

图片
话说 OpenAI 到现在都没有开源过一个模型的代码

肯恩想的是偷偷发育，一骑绝尘

可是 Claude、Gemini 追的紧啊，到现在 GPT 好像也没有什么特别领先的功能

所以 AI 时代，开源的精神显得更加难能可贵

我也很佩服那些勇于开源的公司

正是因为有他们，AI 的发展才能日新月异，一日千里啊

再次向黑森林工作室致敬




以上就是今天分享的主要内容了，如果你觉得阿杰的分享有用，欢迎点一下右下角的「爱心」，推荐给你的朋友们哦~

如果你像阿杰一样喜欢 AI 绘画和 AI 视频，欢迎链接，备注暗号【ZL】，免费领取 AI 资料

图片
最后，阿杰还给大家争取到一个重磅福利，如果你想学 AI，但是害怕踩坑怎么办？
这些其实我们都想到了，为了确保你能获取到真正有价值的AI信息，我们利用合伙人身份，为阿杰的粉丝争取到了一个特殊福利。

那就是 AI破局的 0 元三天体验卡，免费体验AI破局俱乐部的精华内容，进去认真的看看内容适不适合你。

图片


▎往期精彩

01-AI视频

离了大谱。。AI 视频完全免费，无限使用，效果还好

deepseek 做 AI 视频全流程！小白也能轻松学会 | 附成品视频

用 deepseek 做 AI 视频，绝了，和抄作业一样简单！

02-AI绘画

官方再次出手，Midjourney 这下更屌了！

Midjourney 咒语：值得收藏！7 个顶流国风的卷轴效果！

SD 彻底废了。。。




Kontext提示词终极秘籍：单图封神，多图抽卡率翻倍！附2个黑科技技巧
图片
图片
图片
大家好，我是嘟嘟，深耕ComfyUI赛道的程序员。

刚测试完Kontext的提示词玄学！单图效果炸裂，多图抽卡率问题其实能用提示词优化，今天把压箱底的技巧全掏出来，建议收藏细品~

图片
一、Kontext Dev说明
昨天我们介绍了Kontext dev模型的几种使用，包括单图、多图，可以发现在单图情况下使用效果是最强的，多图的话有一些抽卡率问题，我后面又测试了很久确实是这样，其中核心还是提示词，虽然昨天给大家一个通用的大模型提示词脚本，但是对提示词的学习，我感觉还是非常有必要。

今天的话，就再写一篇，围绕提示词技巧，展开说说，并且给出一些好用的优化小技巧，建议大家收藏本篇。

原文指南：https://docs.bfl.ai/guides/prompting_guide_kontext_i2i#general-troubleshooting-tip

二、提示词优化指南
Kontext Dev多图融合技巧（更可控）：https://www.runninghub.cn/post/1939332448016637954?inviteCode=kol01-rh024

2.1 基本对象修改
经过大量的测试，我们发现，Kontext非常擅长直接修改对象。

这里有一个总结：

根据经验，如果每次编辑的指令数量不太复杂，那么让事情更明确是不会有什么坏处。
就是说，尽可能的描述更多细节，能提高最终生成的效果。

2.2 样式迁移技巧
在处理样式传输提示时，下面是常见的三种方式：

a.使用提示词
为特定样式命名 ：不要使用“使其具有艺术性”等模糊术语，而是准确指定您想要的样式（“转换为包豪斯艺术风格”、“转换为水彩画”）

引用已知的艺术家或运动 ：要获得更准确的结果，请包含可识别的风格引用（“文艺复兴时期的绘画风格”、“像 1960 年代的波普艺术海报”）

详细说明关键特征 ：如果命名样式不起作用，最好描述定义样式的视觉元素：

ransform to oil painting with visible brushstrokes, thick paint texture, and rich color depth
保留重要内容 ：明确说明哪些元素不应更改：

在保持原始构图和对象位置的同时，更改为包豪斯艺术风格
图片
图片
b.使用参考图+文本生成
您还可以使用输入图像作为样式引用来生成新图像。

例如：

使用此样式，一只兔子、一只狗和一只猫正在围着一张白色小桌子坐着喝茶
图片
图片
c.使用参考图+原图风格转化
昨天我们也提到过这种方式，就是已经有一张原图，想要参考风格图，让原图发送风格的转化，这也是可以的

将图片女人的绘画风格转换成图2的绘画风格，保持构图不变，只是变风格
图片
2.3 通过提示词进行迭代编辑，保持角色一致性
kontext 擅长保持角色的一致性，即使经过多次编辑。从参考图片开始，我们可以看到角色在整个序列中的一致性。每次编辑使用的提示词都显示在每张图片的标题下方。

图片
保持角色一致性的框架：


“这个人……” 或 “拥有短黑发的女人……”
确立参考角色：首先明确识别你的角色

环境：“……现在位于热带海滩环境”
活动：“……现在在花园里拔杂草”
风格：“转变为粘土动画风格，同时保持相同的角色”
指定变化：清楚地说明哪些方面发生了变化

“……保持相同的面部特征、发型和表情”
“……保持相同的身份和个性”
“……保留他们独特的外貌”
保持身份标识：明确提到哪些特征需要保持一致
❝
常见错误：使用诸如 “她” 这样模糊的指代，而不是 “留着黑色短发的女人”

2.4 文本编辑
Kontext 可以直接编辑图像中的文本，使得更新标志、海报、标签等内容变得简单，无需重新创建整个图像。

编辑文本的最有效方法是使用引号标出你想要更改的具体文本：

提示词结构：将 '[原始文本]' 替换为 '[新文本]'

示例 - 我们可以看到下面的输入图像中写着“Choose joy”，然后我们将“joy”替换为“BFL”——注意 BFL 使用的是大写格式。

图片
文本编辑最佳实践：

尽可能使用清晰易读的字体 ，复杂或风格化的字体可能更难编辑
在需要时指定保留。例如：“ 将 'joy' 替换为 'BFL'，同时保持相同的字体样式和颜色”
保持文本长度相似 - 文本过长或过短可能会影响布局

2.5 视觉提示技巧
这个是个很有意思的小技巧，就是手动添加一些符号，让AI可以快速的识别，比如加一些红色框框，当您想要对图像的特定区域进行有针对性的更改时，这可能特别有用。通过提供视觉标记或参考点，您可以指导模型专注于特定区域。

比如有一张有红框和绿框的图，我可以分别指定局部操作，来看看AI是否识别我的精准指令。

在绿框中添加帽子
图片
在红框中添加帽子
图片
测试绿框的时候一次成功，测试红框的时候好几次会同时生成帽子

其实这里我们可以手动自己通过遮罩来圈定范围，我也经常这么做，这里给出核心添加线框的方案

图片
接一个图像与遮罩预览，然后颜色按我这样写就是红色，图片那边右键在遮罩中打开把想要处理的物体圈出来即可。

remove the red mask section
图片
这样子好像还不能突出这个框选的好处，再找个例子，比如下面这张图，有好多物体，我只用简单的命令移除香水，就会移除2个地方，这样就不精准了。

图片
我指定移除下方第二个香水，这时候就不行了，这种时候就需要我们手动框选物体小技巧了。

移除红框内的香水，其他保持不变
图片
注意，这里测试了3次才成功，我猜可能是我想移除的这个香水太小了，系统不好识别，左上角这个框中一次就成功。

2.6 多图合并提高成功率技巧
其实今天我又测了好多次多图参考的，老实说成功率不是很高，特别是对物理世界实际大小的逻辑参考不合理，昨天也有提过一个小技巧，就是提前做缩放，今天继续教一个小技巧。

我们上面有提到，Kontext单图编辑下效果是最强的，那我们可以结合这一点，提前把一些要融合的东西先整合到一张图里面，然后再利用单图编辑的能力去处理。

核心利用我们以前介绍的FastCanvas这个图像拼接能力，可以指定大小和位置。

图片
继续拿昨天的案例测试看看

让图中小女孩坐在沙发上，地上趴着一只小猫
图片
太强了，我可以随意摆放位置，以及控制角色大小，利用它的单图极强的编辑能力，做出修改。

让图中小女孩躺在沙发上，地上也躺着一只小猫
图片
再换个案例

让图中女人坐在室内环境中，手里拿着l黑色手提包
图片
不错，这种可控的布局，再加上Kontext的强编辑能力，确实让出图质量成功提高了。

这个流也分享到RH上，感兴趣的可以去体验：

Kontext Dev多图融合技巧（更可控）：https://www.runninghub.cn/post/1939332448016637954?inviteCode=kol01-rh024

三、 当结果与预期不符（参考这里）
一般故障排除提示
如果模型正在更改要保持不变的元素，请在提示符中明确说明保留。例如：“ 其他所有内容都应保持黑白” 或“ 保持原始图像的所有其他方面 ”。

角色身份变化太大
在转换一个人时（改变他们的服装、风格或上下文），如果提示不够具体，很容易失去他们独特的身份特征。

尝试更具体地说明身份标记（“保持完全相同的脸、发型和独特特征”）
示例 ：“ 将男子转变为维京战士，同时保留其确切的面部特征、眼睛颜色和面部表情”
构图控制问题
在编辑背景或场景时，你通常希望保持主体的位置、比例和姿势不变。简单的提示词有时会改变这些方面。

简单的提示词导致的不必要变化：

提示词：“他现在在一个阳光明媚的海滩上” → 主体的位置和比例发生变化
图片
提示词：“把他放在海滩上” → 摄像角度和构图发生变化
图片
如果你想精准的控制一致性，提示词应该像下面这样写：

提示词：“将背景更改为海滩，同时保持人物处于完全相同的位置、比例和姿势。保持相同的主体位置、摄像机角度、取景和视角。仅替换他们周围的环境”→更好地保留主体
图片
这个就完全一致，完美，提示词拿去抄作业吧。

为什么会这样？

像 “把他放在海滩上” 这样的模糊指令留给太多的解释。Kontext 可能会选择：

调整取景以匹配典型的海滩照片
更改摄像机角度以显示海滩的更多内容
调整主体位置以更好地适应新设置
样式未正确应用问题
应用某些风格时，简单的提示词可能会产生不一致的结果，或丢失原始构图中的重要元素。我们在上面的例子中可以看到这一点。

基础风格提示可能会丢失重要元素：

提示词：“把它做成素描” → 尽管应用了艺术风格，但一些细节丢失了。
精确的风格提示保持结构：

提示词：“转换为铅笔素描，使用自然的石墨线条、交叉阴影和可见的纸张纹理” → 在应用风格的同时保留了场景。你可以看到更多背景细节，图像中也出现了更多的汽车。
图片
四、最佳实践摘要
具体 ：精确的语言会提供更好的结果。使用准确的颜色名称、详细的描述和清晰的动作动词，而不是模糊的术语。

从简单开始：在增加复杂性之前，先从核心更改开始。首先测试基本编辑，然后在成功的结果的基础上进行构建。Kontext 可以很好地处理迭代编辑，使用它。

有意识地保留 ：明确说明哪些内容应保持不变。使用 “同时保持相同的 [面部特征/构图/照明]” 等短语来保护重要元素

需要时迭代 ：复杂的转换通常需要多个步骤。将戏剧性的更改分解为连续编辑，以便更好地控制。

直接命名主题 ：使用“the woman with short black hair”或“the red car”，而不是“her”、“it”或“this”等代词，以获得更清晰的结果。

对文本使用引号 ：引用要更改的确切文本： 将“joy”替换为“BFL” 比一般文本描述效果更好。

显式控制合成 ：更改背景或设置时，请指定 “保持精确的摄像机角度、位置和取景”，以防止不必要的重新定位。

仔细选择动词 ：“Transform” 可能意味着完全改变，而 “change the clothes” 或 “replace the background” 可以让你更好地控制实际变化的内容。

五、在线使用
云端镜像
大家如果没有本地 ComfyUI 环境，或者本地显卡配置低于 16G 的，可以使用嘟嘟部署的仙宫云镜像，可直接加载使用。后续分享的工作流都会更像到镜像中，一周更新一次，方便大学学习。

目前整合了2个镜像，一个是Flux绘图用的，另外一个是针对视频模型的，之所以分开是一些模型兼容问题，分开比较好处理。

镜像名称：嘟嘟AI绘画趣味学

图片图片

云平台镜像地址：

https://www.xiangongyun.com/image/detail/d961a7dc-ade3-4bd5-a7c6-92ac49ff5e4b?r=37BCLY

https://www.xiangongyun.com/image/detail/81716d29-4461-4b0b-ba4b-7b9b7dd569d3?r=37BCLY

新用户通过邀请码注册，总共可获得 8 元奖励，体验 4 个小时的 4090 作图时长。

RH平台
推荐不想本地自己折腾的同学一个可在线使用Runninghub平台可在线体验AI应用和工作流（注册即送1000积分可用）。

https://www.runninghub.cn/?inviteCode=kol01-rh024

图片
主页更多精彩工作流可在线体验： https://www.runninghub.cn/user-center/1865434314359058434?inviteCode=kol01-rh024

图片
六、总结
以上就是Kontext的一些提示词使用指南以及几个小技巧，非常好用，大家多琢磨提示词用法，Kontext本质就是靠提示词处理的，好的提示词可以大大提高你的出图质量。

技术的迭代是飞快的，要关注最新的消息才不会掉队。

关注我，每天分享最新的ComfyUI技术前沿。

求个三连不过分吧~


推荐阅读
家人们！Kontext-DEV突然开源！12B参数多模态编辑神器，效果直逼Pro版！附全套测试案例
SeedVR2藏了个大招！视频修复很强？模糊图像修复才是真王炸，秒杀Keep/PMRF！（内附实测对比图）
【限时免费】1张图变10张！ComfyUI+Flux黑科技：完美复刻一致性人像，服装发型0偏差！
[ComfyUI]重磅推荐！这款GLM-4大模型插件绝了：智能扩写+图片分析，免费白嫖不占显存！（赠送提示词模版）
用视频生成数字人太麻烦？MultiTalk黑科技：图片+音频直接输出，效果碾压同行！（内附10大案例）
白嫖党狂喜！MiniMax-Remover视频去水印实测：6步干碎动态字幕/浮动logo，效果碾压付费插件！免费在线使用
图片
有粉丝问我是如何学习AI的，我最主要的学习社群是在一个叫AI破局俱乐部的知识星球，目前人员5万多人，包含了最前沿的AI知识信息和相关教程，我同时也是里面的绘画方向的实战教练，每年有4-5次的为期21天的行动营（免费参与）。星球这边最近推出了3天体验卡，我申请到内测资格了。

大家有兴趣可以进去免费看3天，好像还有额外的3天AI实战特训营，别错过。



图片
更多AI绘画相关信息，可关注我的免费知识星球

图片


图片

PS：因公众号平台更改了推送规则，如果不想错过内容，记得读完点一下“在看”，加个“星标”，这样每次新文章推送才会第一时间出现在你的订阅列表里。点“在看”支持我呀，谢谢啦！

Kontext提示词终极秘籍：单图封神，多图抽卡率翻倍！附2个黑科技技巧
图片
图片
图片
大家好，我是嘟嘟，深耕ComfyUI赛道的程序员。

刚测试完Kontext的提示词玄学！单图效果炸裂，多图抽卡率问题其实能用提示词优化，今天把压箱底的技巧全掏出来，建议收藏细品~

图片
一、Kontext Dev说明
昨天我们介绍了Kontext dev模型的几种使用，包括单图、多图，可以发现在单图情况下使用效果是最强的，多图的话有一些抽卡率问题，我后面又测试了很久确实是这样，其中核心还是提示词，虽然昨天给大家一个通用的大模型提示词脚本，但是对提示词的学习，我感觉还是非常有必要。

今天的话，就再写一篇，围绕提示词技巧，展开说说，并且给出一些好用的优化小技巧，建议大家收藏本篇。

原文指南：https://docs.bfl.ai/guides/prompting_guide_kontext_i2i#general-troubleshooting-tip

二、提示词优化指南
Kontext Dev多图融合技巧（更可控）：https://www.runninghub.cn/post/1939332448016637954?inviteCode=kol01-rh024

2.1 基本对象修改
经过大量的测试，我们发现，Kontext非常擅长直接修改对象。

这里有一个总结：

根据经验，如果每次编辑的指令数量不太复杂，那么让事情更明确是不会有什么坏处。
就是说，尽可能的描述更多细节，能提高最终生成的效果。

2.2 样式迁移技巧
在处理样式传输提示时，下面是常见的三种方式：

a.使用提示词
为特定样式命名 ：不要使用“使其具有艺术性”等模糊术语，而是准确指定您想要的样式（“转换为包豪斯艺术风格”、“转换为水彩画”）

引用已知的艺术家或运动 ：要获得更准确的结果，请包含可识别的风格引用（“文艺复兴时期的绘画风格”、“像 1960 年代的波普艺术海报”）

详细说明关键特征 ：如果命名样式不起作用，最好描述定义样式的视觉元素：

ransform to oil painting with visible brushstrokes, thick paint texture, and rich color depth
保留重要内容 ：明确说明哪些元素不应更改：

在保持原始构图和对象位置的同时，更改为包豪斯艺术风格
图片
图片
b.使用参考图+文本生成
您还可以使用输入图像作为样式引用来生成新图像。

例如：

使用此样式，一只兔子、一只狗和一只猫正在围着一张白色小桌子坐着喝茶
图片
图片
c.使用参考图+原图风格转化
昨天我们也提到过这种方式，就是已经有一张原图，想要参考风格图，让原图发送风格的转化，这也是可以的

将图片女人的绘画风格转换成图2的绘画风格，保持构图不变，只是变风格
图片
2.3 通过提示词进行迭代编辑，保持角色一致性
kontext 擅长保持角色的一致性，即使经过多次编辑。从参考图片开始，我们可以看到角色在整个序列中的一致性。每次编辑使用的提示词都显示在每张图片的标题下方。

图片
保持角色一致性的框架：


“这个人……” 或 “拥有短黑发的女人……”
确立参考角色：首先明确识别你的角色

环境：“……现在位于热带海滩环境”
活动：“……现在在花园里拔杂草”
风格：“转变为粘土动画风格，同时保持相同的角色”
指定变化：清楚地说明哪些方面发生了变化

“……保持相同的面部特征、发型和表情”
“……保持相同的身份和个性”
“……保留他们独特的外貌”
保持身份标识：明确提到哪些特征需要保持一致
❝
常见错误：使用诸如 “她” 这样模糊的指代，而不是 “留着黑色短发的女人”

2.4 文本编辑
Kontext 可以直接编辑图像中的文本，使得更新标志、海报、标签等内容变得简单，无需重新创建整个图像。

编辑文本的最有效方法是使用引号标出你想要更改的具体文本：

提示词结构：将 '[原始文本]' 替换为 '[新文本]'

示例 - 我们可以看到下面的输入图像中写着“Choose joy”，然后我们将“joy”替换为“BFL”——注意 BFL 使用的是大写格式。

图片
文本编辑最佳实践：

尽可能使用清晰易读的字体 ，复杂或风格化的字体可能更难编辑
在需要时指定保留。例如：“ 将 'joy' 替换为 'BFL'，同时保持相同的字体样式和颜色”
保持文本长度相似 - 文本过长或过短可能会影响布局

2.5 视觉提示技巧
这个是个很有意思的小技巧，就是手动添加一些符号，让AI可以快速的识别，比如加一些红色框框，当您想要对图像的特定区域进行有针对性的更改时，这可能特别有用。通过提供视觉标记或参考点，您可以指导模型专注于特定区域。

比如有一张有红框和绿框的图，我可以分别指定局部操作，来看看AI是否识别我的精准指令。

在绿框中添加帽子
图片
在红框中添加帽子
图片
测试绿框的时候一次成功，测试红框的时候好几次会同时生成帽子

其实这里我们可以手动自己通过遮罩来圈定范围，我也经常这么做，这里给出核心添加线框的方案

图片
接一个图像与遮罩预览，然后颜色按我这样写就是红色，图片那边右键在遮罩中打开把想要处理的物体圈出来即可。

remove the red mask section
图片
这样子好像还不能突出这个框选的好处，再找个例子，比如下面这张图，有好多物体，我只用简单的命令移除香水，就会移除2个地方，这样就不精准了。

图片
我指定移除下方第二个香水，这时候就不行了，这种时候就需要我们手动框选物体小技巧了。

移除红框内的香水，其他保持不变
图片
注意，这里测试了3次才成功，我猜可能是我想移除的这个香水太小了，系统不好识别，左上角这个框中一次就成功。

2.6 多图合并提高成功率技巧
其实今天我又测了好多次多图参考的，老实说成功率不是很高，特别是对物理世界实际大小的逻辑参考不合理，昨天也有提过一个小技巧，就是提前做缩放，今天继续教一个小技巧。

我们上面有提到，Kontext单图编辑下效果是最强的，那我们可以结合这一点，提前把一些要融合的东西先整合到一张图里面，然后再利用单图编辑的能力去处理。

核心利用我们以前介绍的FastCanvas这个图像拼接能力，可以指定大小和位置。

图片
继续拿昨天的案例测试看看

让图中小女孩坐在沙发上，地上趴着一只小猫
图片
太强了，我可以随意摆放位置，以及控制角色大小，利用它的单图极强的编辑能力，做出修改。

让图中小女孩躺在沙发上，地上也躺着一只小猫
图片
再换个案例

让图中女人坐在室内环境中，手里拿着l黑色手提包
图片
不错，这种可控的布局，再加上Kontext的强编辑能力，确实让出图质量成功提高了。

这个流也分享到RH上，感兴趣的可以去体验：

Kontext Dev多图融合技巧（更可控）：https://www.runninghub.cn/post/1939332448016637954?inviteCode=kol01-rh024

三、 当结果与预期不符（参考这里）
一般故障排除提示
如果模型正在更改要保持不变的元素，请在提示符中明确说明保留。例如：“ 其他所有内容都应保持黑白” 或“ 保持原始图像的所有其他方面 ”。

角色身份变化太大
在转换一个人时（改变他们的服装、风格或上下文），如果提示不够具体，很容易失去他们独特的身份特征。

尝试更具体地说明身份标记（“保持完全相同的脸、发型和独特特征”）
示例 ：“ 将男子转变为维京战士，同时保留其确切的面部特征、眼睛颜色和面部表情”
构图控制问题
在编辑背景或场景时，你通常希望保持主体的位置、比例和姿势不变。简单的提示词有时会改变这些方面。

简单的提示词导致的不必要变化：

提示词：“他现在在一个阳光明媚的海滩上” → 主体的位置和比例发生变化
图片
提示词：“把他放在海滩上” → 摄像角度和构图发生变化
图片
如果你想精准的控制一致性，提示词应该像下面这样写：

提示词：“将背景更改为海滩，同时保持人物处于完全相同的位置、比例和姿势。保持相同的主体位置、摄像机角度、取景和视角。仅替换他们周围的环境”→更好地保留主体
图片
这个就完全一致，完美，提示词拿去抄作业吧。

为什么会这样？

像 “把他放在海滩上” 这样的模糊指令留给太多的解释。Kontext 可能会选择：

调整取景以匹配典型的海滩照片
更改摄像机角度以显示海滩的更多内容
调整主体位置以更好地适应新设置
样式未正确应用问题
应用某些风格时，简单的提示词可能会产生不一致的结果，或丢失原始构图中的重要元素。我们在上面的例子中可以看到这一点。

基础风格提示可能会丢失重要元素：

提示词：“把它做成素描” → 尽管应用了艺术风格，但一些细节丢失了。
精确的风格提示保持结构：

提示词：“转换为铅笔素描，使用自然的石墨线条、交叉阴影和可见的纸张纹理” → 在应用风格的同时保留了场景。你可以看到更多背景细节，图像中也出现了更多的汽车。
图片
四、最佳实践摘要
具体 ：精确的语言会提供更好的结果。使用准确的颜色名称、详细的描述和清晰的动作动词，而不是模糊的术语。

从简单开始：在增加复杂性之前，先从核心更改开始。首先测试基本编辑，然后在成功的结果的基础上进行构建。Kontext 可以很好地处理迭代编辑，使用它。

有意识地保留 ：明确说明哪些内容应保持不变。使用 “同时保持相同的 [面部特征/构图/照明]” 等短语来保护重要元素

需要时迭代 ：复杂的转换通常需要多个步骤。将戏剧性的更改分解为连续编辑，以便更好地控制。

直接命名主题 ：使用“the woman with short black hair”或“the red car”，而不是“her”、“it”或“this”等代词，以获得更清晰的结果。

对文本使用引号 ：引用要更改的确切文本： 将“joy”替换为“BFL” 比一般文本描述效果更好。

显式控制合成 ：更改背景或设置时，请指定 “保持精确的摄像机角度、位置和取景”，以防止不必要的重新定位。

仔细选择动词 ：“Transform” 可能意味着完全改变，而 “change the clothes” 或 “replace the background” 可以让你更好地控制实际变化的内容。

五、在线使用
云端镜像
大家如果没有本地 ComfyUI 环境，或者本地显卡配置低于 16G 的，可以使用嘟嘟部署的仙宫云镜像，可直接加载使用。后续分享的工作流都会更像到镜像中，一周更新一次，方便大学学习。

目前整合了2个镜像，一个是Flux绘图用的，另外一个是针对视频模型的，之所以分开是一些模型兼容问题，分开比较好处理。

镜像名称：嘟嘟AI绘画趣味学

图片图片

云平台镜像地址：

https://www.xiangongyun.com/image/detail/d961a7dc-ade3-4bd5-a7c6-92ac49ff5e4b?r=37BCLY

https://www.xiangongyun.com/image/detail/81716d29-4461-4b0b-ba4b-7b9b7dd569d3?r=37BCLY

新用户通过邀请码注册，总共可获得 8 元奖励，体验 4 个小时的 4090 作图时长。

RH平台
推荐不想本地自己折腾的同学一个可在线使用Runninghub平台可在线体验AI应用和工作流（注册即送1000积分可用）。

https://www.runninghub.cn/?inviteCode=kol01-rh024

图片
主页更多精彩工作流可在线体验： https://www.runninghub.cn/user-center/1865434314359058434?inviteCode=kol01-rh024

图片
六、总结
以上就是Kontext的一些提示词使用指南以及几个小技巧，非常好用，大家多琢磨提示词用法，Kontext本质就是靠提示词处理的，好的提示词可以大大提高你的出图质量。

技术的迭代是飞快的，要关注最新的消息才不会掉队。

关注我，每天分享最新的ComfyUI技术前沿。

求个三连不过分吧~


推荐阅读
家人们！Kontext-DEV突然开源！12B参数多模态编辑神器，效果直逼Pro版！附全套测试案例
SeedVR2藏了个大招！视频修复很强？模糊图像修复才是真王炸，秒杀Keep/PMRF！（内附实测对比图）
【限时免费】1张图变10张！ComfyUI+Flux黑科技：完美复刻一致性人像，服装发型0偏差！
[ComfyUI]重磅推荐！这款GLM-4大模型插件绝了：智能扩写+图片分析，免费白嫖不占显存！（赠送提示词模版）
用视频生成数字人太麻烦？MultiTalk黑科技：图片+音频直接输出，效果碾压同行！（内附10大案例）
白嫖党狂喜！MiniMax-Remover视频去水印实测：6步干碎动态字幕/浮动logo，效果碾压付费插件！免费在线使用
图片
有粉丝问我是如何学习AI的，我最主要的学习社群是在一个叫AI破局俱乐部的知识星球，目前人员5万多人，包含了最前沿的AI知识信息和相关教程，我同时也是里面的绘画方向的实战教练，每年有4-5次的为期21天的行动营（免费参与）。星球这边最近推出了3天体验卡，我申请到内测资格了。

大家有兴趣可以进去免费看3天，好像还有额外的3天AI实战特训营，别错过。



图片
更多AI绘画相关信息，可关注我的免费知识星球

图片


图片

PS：因公众号平台更改了推送规则，如果不想错过内容，记得读完点一下“在看”，加个“星标”，这样每次新文章推送才会第一时间出现在你的订阅列表里。点“在看”支持我呀，谢谢啦！




能力释放！超准超快超高效，flux kontext最强组合：flux kontext+提示词助手+标注+nunchakku，完美
图片

更多AI前沿科技资讯，请关注我们：

【closerAI ComfyUI】能力释放！超准超快超高效，flux kontext最强组合：flux kontext+提示词助手+标注+nunchakku，完美！
大家好，我是Jimmy。
探索flux kontext也几天了，前后分享了使用的心得：
【closerAI ComfyUI】重磅来袭！flux kontext dev开源！图像编辑全民普及化！GGUF版本4G可玩！冲
【closerAI ComfyUI】flux kontext dev提示词指南，同时探索controlnet控制一起生成的可行性
【closerAI ComfyUI】flux kontext dev 多图融合进阶技巧！提高融合概率的方法技巧，建议收藏学习！赞
三篇文章，分别分享了：
1、低显存使用GGUF，4G显存本地运行flux kontet;
2、熟练flux kontext 的提示词规则同时探索controlnet的相互结合使用；
3、flux kontext提示词生成网页应用辅助优化提示词，精准生图，同时使用多图分别串联+NAG的方式进行多图融合的高级技巧；
为了能再充分发挥kontext的能力，结合人性弱点（提示词不可能写得完整的弱点），我这里探索出一个能释放flux kontext能力的工作流。这是我自己认为目前以来最优的，不喜勿喷。因为这玩意本身没有“正确答案”，符合自身需要和工作习惯，就是好答案。
我的工作流的解决方案是：
1、使用flux kontext nunchaku 
2、工作流使用串联与结联在nunchaku版本下出两个结果，选择最优输出；
3、开发flux kontext提示词生成器（网页应用+comfyUI节点），解决费脑写提示词的效率问题和不精准问题；
4、开发图像标注和涂鸦应用（网页应用+comfyUI节点），充分发挥kontext编辑能力；
以下，我详细分享下。以下是我们搭建的工作流：

flux kontext单图编辑超高效工作流（flux kontext+提示词助手+标注+nunchakku）：

图片
工作流主要模块如上图示：

1、flux kontext nunchaku

使用nunchaku,绝对是最好的选择，使用方法很简单了

https://github.com/mit-han-lab/ComfyUI-nunchaku

1）更新节点。下载解压放：comfyUI/custom_nodes下

图片
2）下载kontext nunchaku模型，

https://huggingface.co/mit-han-lab/nunchaku-flux.1-kontext-dev/tree/main

图片
图片
如上图示下载符合你设备的版本。放置comfyUI/models/unet下

3）安装轮子


https://github.com/mit-han-lab/nunchaku/releases

图片
它符合你设备及comfyUI版本的轮子下载放comfyUI/python下

图片
空白处右键打开终端输入命令：

python.exe pip -m install 拖入轮子  就会自动显示路径的了，回车执行即可。

图片
最后重启即可使用了。

2、图片标注处理

这是我自己开发的节点，也提供网页应用。

节点安装很简单，下载后解压放置custom_nodes下。

图片
这个重用是什么？视觉识别！kontext有视觉能力，框住一个区域，提示修改想法，它就能修改。

我执行一个给大家看：标注好，执行。

提示词写入：在红框加入与图片风格一致的魔法师帽子。

然后提示词优化后：在红色的方框里，添加一顶与图像风格一致的魔法师帽子

图片
经过kontext nunchaku后：分别生成串联与联结的结果：

加入不同颜色的框标注，描述修改的内容：

图片
图片
图片
这里注意，联结方式，在多框处理时出图更好。所以这是我为何加入串联与联结一起生图的原因之一。因为不同任务下各有好坏。一次出两个结果，选择最优值。

当然，不一定使用我开发的节点来处理标注图的，可以在我的网页应用上或者其它comfyUI节点，或是PS工具先处理也行。

我开发的提示词生成器网页应用：http://aigc.douyoubuy.cn/closerai-flux-kontext/

图片
添加图片后标注方框，下载即可。



comfyUI kontext 标注助手节点：
http://closerai.douyoubuy.cn/2025/07/01/2089/





3、kontext提示词优化生成器

图片
这个节点我在另一个号介绍过，

【closerAI ComfyUI】kontext提示词生成器！懒人福音，一键转成kontext规则提示词，从此无脑操作编辑图像


现在迭代到V1.2版本

增加更丰富的参数控制。

这个节点就是让我们输入修改内容后转换成kontext规则的提示词

同时具备翻译功能，同时也内置各种转换风格：

图片
光影：

图片
姿势：

图片
相机视角：
图片
简单操作选择，就能形成提示词，高效方便。

comfyUI kontext提示词生成器节点：

http://aigc.douyoubuy.cn/2025/06/30/2062/



comfyUI kontext提示词生成器网页应用：

http://aigc.douyoubuy.cn/closerai-flux-kontext/



4、串联与结联方式

不用多说，正是因为nunchaku支持了kontext。在秒级间出图，速度超快，所以，两种方式都用，因为不同任务下，能力各有好坏，一次出两张图，选择最优的结果。

所以，整套组合拳下来，高效！

图片
图片


本地算力不够怎么办？

如果本地设备算力不好的小伙伴，推荐使用线上comfyUI来运行体验：runninghub.cn

图片
Flux Kontext Dev动嘴P图流体验地址：

https://www.runninghub.cn/ai-detail/1938445554957639681

注册地址：https://www.runninghub.cn/?utm_source=kol01-RH151 
通过这个链接第一次注册送1000点，每日登录送100点



最后几句：

这个工作流围绕kontext，打造完美体验与释放模型能力，提高效率，达到生产力水平。唯一！缺点是，nunchaku kontext不支持NAG，负面提示词不生效，如果支持了，生图质量与精准性将会提高！

以上是closerAI团队制作的stable diffusion comfyUI closerAI开发的节点，以及closerAI kontext单图编辑工作流（flux kontext+提示词助手+标注+nunchakku)介绍，大家可以根据工作流思路进行尝试搭建。

当然，也可以在我们closerAI会员站上获取对应的工作流(查看原文)。

以上，既然看到这里了，如果觉得不错，随手点个赞、在看、转发三连吧，如果想第一时间收到推送，也可以给我个星标⭐～谢谢你看我的文章，我们，下次再见。

>/ 作者：JimmyMo

更多AI前沿科技资讯，请关注我们：

图片