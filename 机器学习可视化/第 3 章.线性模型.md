---
pubDate: 2024-07-25
description: 深入剖析感知器与Logistic回归两种经典线性模型。通过从零实现、3D可视化及创新的交互式沙盘，直观理解线性决策边界与概率曲面的构建与优化过程。
---

# 第 3 章. 线性模型

线性模型是机器学习领域的基石，它们以其简洁、高效和强大的可解释性，构成了许多更复杂算法的核心。本章，我们将深入探索两种奠基性的线性分类模型：感知器（Perceptron）和 Logistic 回归（Logistic Regression）。我们将不仅从零开始实现它们，还将通过动态可视化和全新的交互式沙盘，来直观地解构其工作原理。

## 3.1 感知器 (Perceptron)

感知器算法是最早的监督学习算法之一，它为线性二分类问题提供了一个优雅的解决方案。其目标是找到一个超平面（Hyperplane），将两种不同类别的数据点完美地分离开来。

### 3.1.1 任务设定：线性可分数据集

为了演示感知器的工作，我们首先生成一个三维的、线性可分的数据集。这些点根据它们在由一个目标法向量 `target_normal_vector` 定义的超平面的哪一侧，被赋予 `+1` 或 `-1` 的标签。

```python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from celluloid import Camera
import scienceplots
from IPython.display import Image

np.random.seed(0)
plt.style.use(["science", "no-latex"])

def generate_dataset(dims, normal_vector):
    """
    根据给定的法向量，在三维空间中生成一个线性可分的数据集。

    Args:
        dims (int): 在每个维度上生成的点的数量。
        normal_vector (np.ndarray): 定义决策超平面的法向量。

    Returns:
        tuple: 包含网格坐标(X, Y, Z)、特征矩阵和标签的元组。
    """
    points = np.linspace(-1, 1, dims)
    X, Y, Z = np.meshgrid(points, points, points)
    features = np.column_stack((X.ravel(), Y.ravel(), Z.ravel()))
    
    # 点到由原点和法向量定义的平面的距离决定了其标签
    distances = np.dot(features, normal_vector)
    labels = np.where(distances >= 0, 1, -1)
    return X, Y, Z, features, labels

# 定义目标超平面的法向量
target_normal_vector = np.array([1.0, 1.0, 1.0])
target_normal_vector = target_normal_vector / np.linalg.norm(target_normal_vector)

scaling = 5
X, Y, Z, features, labels = generate_dataset(scaling, target_normal_vector)

# 绘制数据集
fig = plt.figure()
ax = fig.add_subplot(111, projection="3d")
ax.scatter(features[:,0], features[:,1], features[:,2], marker='o', alpha=0.3, c=labels)
ax.set_title("Linearly Separable 3D Dataset")
plt.show()
```
![Linearly Separable 3D Dataset](../_images/142302f279d8409e8bfa9a2f32ed8441999220caa19018968b3690c9ccf11575.png)

### 3.1.2 核心理论

#### 超平面 (Hyperplane)
在三维空间中，超平面就是一个普通的二维平面。它的方程由其法向量 `w = (w_x, w_y, w_z)` 和偏置 `b` 定义。对于空间中任意一点 `x = (x, y, z)`，它都满足方程：
$$
w \cdot x + b = 0 \implies w_x x + w_y y + w_z z + b = 0
$$
感知器学习的目标，就是找到这个最佳的法向量 `w` 和偏置 `b`。

#### 损失函数：Hinge Loss
为了量化模型的预测有多差，感知器使用**铰链损失 (Hinge Loss)**。对于单个样本 `(x, y)`，其中 `y` 是真实标签 `{-1, 1}`，损失定义为：
$$
L(w, b) = \max(0, -y \cdot (w \cdot x + b))
$$
这个公式的直觉是：
-   如果一个点被正确分类（即 `y \cdot (w \cdot x + b) > 0`），那么损失为 0。
-   如果一个点被错误分类（即 `y \cdot (w \cdot x + b) < 0`），那么损失就是 `-y \cdot (w \cdot x + b)`，这个值与该点被错误分类的“程度”成正比。

#### 梯度计算
为了使用梯度下降优化参数，我们需要计算铰链损失对 `w` 和 `b` 的梯度：
-   **对 `b` 的梯度**:
    $$
    \frac{\partial L}{\partial b} = \begin{cases} -y & \text{if } y(w \cdot x + b) \le 0 \\ 0 & \text{otherwise} \end{cases}
    $$
-   **对 `w` 的梯度**:
    $$
    \frac{\partial L}{\partial w} = \begin{cases} -y \cdot x & \text{if } y(w \cdot x + b) \le 0 \\ 0 & \text{otherwise} \end{cases}
    $$
可以看到，只有当点被错分时，才会有非零的梯度，模型才会进行更新。

```python
def hinge_loss(w, x, b, y):
    return max(0.0, -y * (np.dot(w, x) + b))

def hinge_loss_db(w, x, b, y):
    if y * (np.dot(w, x) + b) <= 0.0:
        return -y
    return 0

def hinge_loss_dw(w, x, b, y):
    if y * (np.dot(w, x) + b) <= 0.0:
        return -y * x
    return np.zeros_like(x)
```

### 3.1.3 代码实现

我们将梯度下降的逻辑封装在一个函数中，并在一个 `fit` 函数中迭代训练。

```python
def gradient_descent_perceptron(weights, x, bias, y, learning_rate):
    """
    执行单步感知器的梯度下降更新。

    Args:
        weights (np.ndarray): 当前的权重向量。
        x (np.ndarray): 单个输入特征向量。
        bias (float): 当前的偏置项。
        y (int): 真实的标签 (-1 或 1)。
        learning_rate (float): 学习率。

    Returns:
        tuple: 更新后的权重和偏置。
    """
    weights = weights - learning_rate * hinge_loss_dw(weights, x, bias, y)
    bias = bias - learning_rate * hinge_loss_db(weights, x, bias, y)
    return weights, bias

def generate_hyperplane(scaling, normal_vector):
    """
    根据法向量生成用于可视化的超平面坐标点。

    Args:
        scaling (int): 平面网格的精细度。
        normal_vector (np.ndarray): 超平面的法向量。

    Returns:
        tuple: 包含超平面上点的x, y, z坐标的元组。
    """
    points = np.linspace(-1, 1, scaling)
    xx, yy = np.meshgrid(points, points)
    zz = -(normal_vector[0] * xx + normal_vector[1] * yy) / normal_vector[2]
    return xx, yy, zz

def create_plots_perceptron():
    """
    创建并初始化用于感知器训练过程可视化的 Matplotlib 图形和子图。

    Returns:
        tuple: 包含各个子图句柄和 Camera 对象的元组。
    """
    fig, ax = plt.subplots(2, 3, figsize=(16 / 9.0 * 4, 4 * 1), layout="constrained")
    fig.suptitle("Perceptron")

    ax[0, 0].set_xlabel("Epoch", fontweight="normal")
    ax[0, 0].set_ylabel("Error", fontweight="normal")
    ax[0, 0].set_title("Hinge Loss")
    ax[1, 0].set_xlabel("Z, Distance to Hyperplane", fontweight="normal")
    ax[1, 0].set_ylabel("", fontweight="normal")
    ax[1, 0].set_title("Linear Transformation")
    ax[0, 1].axis("off"); ax[0, 2].axis("off"); ax[1, 1].axis("off"); ax[1, 2].axis("off")

    ax[1, 2] = fig.add_subplot(1, 2, 2, projection="3d")
    ax[1, 2].set_xlabel("X"); ax[1, 2].set_ylabel("Y"); ax[1, 2].set_zlabel("Z")
    ax[1, 2].set_title("Hyperplane Decision Boundary")
    ax[1, 2].view_init(20, -35)
    ax[1, 2].set_xlim(-1, 1); ax[1, 2].set_ylim(-1, 1); ax[1, 2].set_zlim(-1, 1)

    camera = Camera(fig)
    return ax[0, 0], ax[1, 0], ax[1, 2], camera

def plot_graphs_perceptron(ax0, ax1, ax2, idx, visible_err, err_idx, errors, scaling, target_normal_vector, predictions, features, labels, weights):
    """
    在给定的子图上绘制感知器训练的单帧可视化。

    Args:
        ax0 (plt.Axes): 用于绘制损失曲线的子图。
        ax1 (plt.Axes): 用于绘制线性变换的子图。
        ax2 (plt.Axes): 用于绘制3D决策边界的子图。
        idx (int): 当前的迭代次数。
        visible_err (np.ndarray): 误差可见性掩码。
        err_idx (np.ndarray): 迭代次数索引数组。
        errors (np.ndarray): 记录的误差数组。
        scaling (int): 数据集和超平面的缩放比例。
        target_normal_vector (np.ndarray): 真实决策边界的法向量。
        predictions (np.ndarray): 当前模型的预测输出。
        features (np.ndarray): 训练特征。
        labels (np.ndarray): 真实标签。
        weights (np.ndarray): 当前模型的权重。
    """
    ax0.plot(err_idx[visible_err][: idx + 1], errors[visible_err][: idx + 1], color="red")
    
    # 绘制真实决策边界
    xx_target, yy_target, zz_target = generate_hyperplane(scaling, target_normal_vector)
    ground_truth_legend = ax2.plot_surface(xx_target, yy_target, zz_target, color="red", alpha=0.2, label="Ground Truth")
    ax2.quiver(0, 0, 0, target_normal_vector[0], target_normal_vector[1], target_normal_vector[2], color="red", length=1, arrow_length_ratio=0.1)

    # 绘制预测决策边界
    xx, yy, zz = generate_hyperplane(scaling, weights)
    predictions_legend = ax2.plot_surface(xx, yy, zz, color="blue", alpha=0.2, label="Prediction")
    ax2.quiver(0, 0, 0, weights[0], weights[1], weights[2], color="blue", length=1, arrow_length_ratio=0.1)

    # 绘制数据点
    def generate_colors(arr): return ["green" if d >= 0 else "orange" for d in arr]
    predictions_colors = generate_colors(predictions)
    predictions_norm = np.maximum(1 - np.exp(-(predictions**2)), 0.2)
    ax2.scatter(features[:, 0], features[:, 1], features[:, 2], c=predictions_colors, marker="o", alpha=predictions_norm)
    ax2.legend((ground_truth_legend, predictions_legend), ("Ground Truth", "Predictions"), loc="upper left")

    # 绘制线性变换图
    ground_truth_colors = generate_colors(labels)
    ax1.scatter(predictions, np.zeros(predictions.shape), c=ground_truth_colors, marker="o", alpha=0.3)

def fit_perceptron(weights, bias, target_normal_vector, features, labels, X, Y, Z, scaling, epochs, learning_rate, optimizer, output_filename):
    """
    训练感知器模型并通过动画可视化训练过程。

    Args:
        weights (np.ndarray): 初始权重。
        bias (float): 初始偏置。
        target_normal_vector (np.ndarray): 真实决策边界的法向量。
        features (np.ndarray): 训练特征。
        labels (np.ndarray): 真实标签。
        X, Y, Z: 数据集的网格坐标。
        scaling (int): 缩放比例。
        epochs (int): 训练的总轮数。
        learning_rate (float): 学习率。
        optimizer (function): 用于更新参数的优化器函数。
        output_filename (str): 输出动画的文件名。
    """
    err_idx = np.arange(1, epochs + 1)
    errors = np.full(epochs, -1)
    ax0, ax1, ax2, camera = create_plots_perceptron()

    for idx in range(epochs):
        error = 0
        predictions = np.array([])
        for x, y in zip(features, labels):
            output = np.dot(weights, x) + bias
            predictions = np.append(predictions, output)
            error += hinge_loss(weights, x, bias, y)
            weights, bias = optimizer(weights, x, bias, y, learning_rate)

        error /= len(X)
        weights = weights / np.linalg.norm(weights)

        # 为了优化动画的生成，我们不需要为每一轮都生成一帧。
        # 这里我们选择在训练早期（<15轮）更频繁地采样，在中期（<50轮）降低频率，
        # 在后期则大幅降低采样频率，从而生成一个大小合适且能清晰展示关键学习阶段的动画。
        if (idx < 5 or (idx < 15 and idx % 2 == 0) or (idx <= 50 and idx % 10 == 0) or (idx <= 1000 and idx % 20 == 0) or idx % 250 == 0):
            print(f"epoch: {idx}, Hinge Loss: {error}")
            errors[idx] = error
            visible_err = errors != -1
            plot_graphs_perceptron(ax0, ax1, ax2, idx, visible_err, err_idx, errors, scaling, target_normal_vector, predictions, features, labels, weights)
            camera.snap()

    animation = camera.animate()
    animation.save(output_filename, writer="pillow")
    plt.show()
```

### 3.1.4 训练与可视化

现在，我们将所有部分组合起来，训练我们的感知器模型。

```python
# 初始化权重和偏置
weights = np.array([1.0, -1.0, -1.0])
weights = weights / np.linalg.norm(weights)
bias = 0
epochs = 301
learning_rate = 0.0005

# 执行训练
output_filename = "perceptron.gif"
fit_perceptron(weights, bias, target_normal_vector, features, labels, X, Y, Z, scaling, epochs, learning_rate, gradient_descent_perceptron, output_filename)
```
**训练过程输出:**
```
epoch: 0, Hinge Loss: 9.314269414709884
epoch: 1, Hinge Loss: 9.227024830601328
...
epoch: 160, Hinge Loss: 0.018715050957433404
epoch: 180, Hinge Loss: 0.0
```
![Perceptron Training Visualization](../_images/906771d7aec69c46fb7e0ffd8a07a9c381c01d17802319f8659fc645006fd8fe.png)

最终生成的动画 `perceptron.gif` 直观地展示了整个学习过程：
-   **右侧3D图**: 蓝色的预测超平面（及其法向量）如何从一个错误的初始位置，逐步旋转、调整，最终与红色的真实超平面近乎完美地重合。数据点也根据当前的预测边界被着色。
-   **左上角图**: Hinge Loss 随着迭代次数的增加而迅速下降，最终达到 0，表明所有点都已被正确分类。
-   **左下角图**: 这是一个有趣的“线性变换”视图，它将3D点投影到1D空间（即点到当前决策边界的距离）。可以看到，随着训练的进行，所有橙色点（标签-1）和绿色点（标签+1）被清晰地推向了 0 点的两侧。

![Perceptron Animation](../_images/c2c62a2faf9e9900ea7c310c06b51a2aaa4961eea4ac747e4514711e278c10cc.gif)

### 3.1.5 交互式感知器：手动调整决策边界

除了观察算法自动学习，我们还可以通过一个交互式沙盘来手动“扮演”优化算法的角色，从而建立更深刻的直觉。

![交互式感知器](../_images/interactive_perceptron.png)

在这个界面中：
-   **滑块**: 你可以直接拖动滑块来调整法向量 `w` 的三个分量 `x, y, z` 以及偏置 `b`。
-   **3D视图**:
    -   **红色平面**: 代表了数据集的“真实”决策边界。
    -   **蓝色平面**: 代表了由你当前滑块参数定义的“预测”决策边界。
    -   **数据点**: 绿色代表一类，橙色代表另一类。

**你的任务**: 尝试手动调整四个滑块，目标是让蓝色的预测平面与红色的真实平面重合，从而使得所有数据点都被正确地分割开。这个手动寻找最佳参数的过程，正是梯度下降算法自动化实现的核心思想。

---

## 3.2 Logistic 回归 (Logistic Regression)

与感知器输出“是”或“否”的硬分类不同，Logistic 回归是一个更“柔和”的模型。它输出的是一个概率值（例如，一个病人患有某种疾病的概率是 80%），这使其在许多现实场景中更为实用。

### 3.2.1 任务设定：乳腺癌数据集分类

我们将使用经典的乳腺癌数据集。任务是根据肿瘤的两个特征（例如“平均周长”和“平均半径”），来预测该肿瘤是恶性（malignant）还是良性（benign）。

```python
import autograd.numpy as np # 使用autograd版本的numpy以支持自动求导
from autograd import grad
import sklearn.datasets as skdatasets

dataset = skdatasets.load_breast_cancer()

features_used = [-3, -8]
X = dataset.data[:, features_used]
feature_names = dataset.feature_names[features_used]

# 对特征进行Min-Max归一化
X_min_vals = X.min(axis=0)
X_max_vals = X.max(axis=0)
X = (X - X_min_vals) / (X_max_vals - X_min_vals)

Y = dataset.target # 0: 恶性, 1: 良性
```

### 3.2.2 核心理论

#### Sigmoid 激活函数
Logistic 回归的核心是将线性模型的输出“压缩”到 (0, 1) 区间内，使其成为一个合法的概率值。这个神奇的“压缩”工具就是 **Sigmoid 函数**:
$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$
其中 `z` 是线性部分的输出，即 $z = w \cdot x + b$。

#### Sigmoid 的梯度与 Autograd
在进行梯度下降时，我们需要 Sigmoid 函数的导数。其导数有一个非常优美的性质，可以表示为它自身的函数：
$$
\sigma'(z) = \sigma(z)(1 - \sigma(z))
$$
我们可以手动实现这个导数，但一个更现代、更不容易出错的方法是使用自动微分（Automatic Differentiation）库，例如 `autograd`。`autograd` 可以追踪 `numpy` 的计算过程并自动计算任意函数的梯度。

```python
# 使用 autograd 自动计算梯度
# grad() 用于标量输入, egrad() (elementwise_grad) 用于矢量化输入
from autograd import egrad
sigmoid_prime_autograd = egrad(sigmoid)

# 我们可以验证 autograd 的结果与手动计算一致
sigmoid_prime_manual = lambda x: sigmoid(x) * (1 - sigmoid(x))
x_test = np.linspace(-10, 10, 100)
assert np.allclose(sigmoid_prime_autograd(x_test), sigmoid_prime_manual(x_test))
print("Autograd calculation for Sigmoid's gradient is correct.")
```
在更复杂的模型中，手动推导和实现梯度既繁琐又容易出错，`autograd` 这样的工具因此成为了现代机器学习框架的标配。

#### 损失函数：二元交叉熵 (Binary Cross-Entropy)
对于概率模型，我们通常使用**最大似然估计 (Maximum Likelihood Estimation)** 来推导其损失函数。其基本思想是：找到一组参数 `(w, b)`，使得我们观测到的这个训练数据集（即所有样本的真实标签）出现的概率最大。

对于单个样本 `(x, y)`，其预测为真实标签 `y` 的概率可以写成一个巧妙的式子（这也被称为伯努利分布的概率质量函数）：
$$
P(y|x) = \hat{y}^y \cdot (1-\hat{y})^{1-y}
$$
其中 $\hat{y} = \sigma(w \cdot x + b)$ 是模型预测为正类（y=1）的概率。

整个数据集的似然函数就是所有样本概率的乘积。为了计算方便，我们通常优化其**对数似然**。而机器学习中习惯于“最小化损失”，所以我们对“负对数似然”进行最小化，再取所有样本的平均值，这就得到了**二元交叉熵 (BCE) 损失函数**:
$$
J(w, b) = - \frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)}) \right]
$$

#### 梯度计算
为了使用梯度下降最小化损失函数 $J(w,b)$，我们需要计算它对参数 $w$ 和 $b$ 的偏导数。推导过程的核心是链式法则。

首先，我们将损失函数 $J$ 对预测值 $\hat{y}$ 求导：
$$
\frac{\partial J}{\partial \hat{y}} = - \left( \frac{y}{\hat{y}} - \frac{1-y}{1-\hat{y}} \right) = \frac{\hat{y}-y}{\hat{y}(1-\hat{y})}
$$
接着，我们将预测值 $\hat{y} = \sigma(z)$ 对线性输出 $z$ 求导，这正是我们之前讨论过的 Sigmoid 梯度：
$$
\frac{\partial \hat{y}}{\partial z} = \sigma'(z) = \sigma(z)(1-\sigma(z)) = \hat{y}(1-\hat{y})
$$
最后，我们将线性输出 $z=w \cdot x + b$ 分别对 $w$ 和 $b$ 求导：
$$
\frac{\partial z}{\partial w} = x \quad \text{and} \quad \frac{\partial z}{\partial b} = 1
$$
根据链式法则，将以上三项相乘，我们得到了一个异常简洁的结果：
$$
\frac{\partial J}{\partial z} = \frac{\partial J}{\partial \hat{y}} \frac{\partial \hat{y}}{\partial z} = \frac{\hat{y}-y}{\hat{y}(1-\hat{y})} \cdot \hat{y}(1-\hat{y}) = \hat{y}-y
$$
现在，计算对 $w$ 和 $b$ 的梯度就非常直接了：
-   **对 `w` 的梯度**:
    $$
    \frac{\partial J}{\partial w} = \frac{\partial J}{\partial z} \frac{\partial z}{\partial w} = (\hat{y}-y)x
    $$
-   **对 `b` 的梯度**:
    $$
    \frac{\partial J}{\partial b} = \frac{\partial J}{\partial z} \frac{\partial z}{\partial b} = \hat{y}-y
    $$
在实践中，我们会对所有样本的梯度取平均值。

```python
sigmoid = lambda x: 1 / (1 + np.exp(-x))

def bce(y_true, y_pred):
    return -np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

def bce_dw(x, y_true, y_pred):
    return np.mean(x * (y_pred - y_true))

def bce_db(y_true, y_pred):
    return np.mean(y_pred - y_true)
```

### 3.2.3 代码实现

实现过程与感知器类似，只是替换了损失函数和梯度计算的逻辑。

```python
def gradient_descent_logistic(weights, x, bias, y_true, y_pred, learning_rate):
    """
    执行单步 Logistic 回归的梯度下降更新。

    Args:
        weights (np.ndarray): 当前的权重向量。
        x (np.ndarray): 单个输入特征向量。
        bias (float): 当前的偏置项。
        y_true (int): 真实的标签 (0 或 1)。
        y_pred (float): 模型对当前样本的预测概率。
        learning_rate (float): 学习率。

    Returns:
        tuple: 更新后的权重和偏置。
    """
    # 注意：这里的 bce_dw 和 bce_db 内部已经实现了对所有样本求平均的逻辑
    # 但在随机梯度下降(SGD)的单样本更新中，我们直接使用 (y_pred - y_true) * x
    # 为保持与原文代码逻辑一致，此处仍使用原文函数
    weights = weights - learning_rate * bce_dw(x, y_true, y_pred)
    bias = bias - learning_rate * bce_db(y_true, y_pred)
    return weights, bias

def create_plots_logistic():
    """
    创建并初始化用于 Logistic 回归训练过程可视化的 Matplotlib 图形和子图。

    Returns:
        tuple: 包含各个子图句柄和 Camera 对象的元组。
    """
    fig, ax = plt.subplots(1, 3, figsize=(16 / 9.0 * 4, 4 * 1))
    fig.suptitle("Logistic Regression")

    ax[0].set_xlabel("Epoch", fontweight="normal")
    ax[0].set_ylabel("Error", fontweight="normal")
    ax[0].set_title("Binary Cross Entropy Error")
    ax[1].axis("off"); ax[2].axis("off")

    ax[2] = fig.add_subplot(1, 2, 2, projection="3d")
    ax[2].set_xlabel("X"); ax[2].set_ylabel("Y"); ax[2].set_zlabel("Z")
    ax[2].set_title("Prediction Probabilities")
    ax[2].view_init(20, -35)
    
    camera = Camera(fig)
    return ax[0], ax[2], camera

def plot_graphs_logistic(ax0, ax1, idx, visible_mse, mse_idx, errors, features, labels, predictions, points_x, points_y, surface_predictions, dims):
    """
    在给定的子图上绘制 Logistic 回归训练的单帧可视化。
    Args:
        ax0 (plt.Axes): 用于绘制损失曲线的子图。
        ax1 (plt.Axes): 用于绘制3D概率曲面的子图。
        idx (int): 当前的迭代次数。
        visible_mse (np.ndarray): 误差可见性掩码。
        mse_idx (np.ndarray): 迭代次数索引数组。
        errors (np.ndarray): 记录的误差数组。
        features (np.ndarray): 训练特征。
        labels (np.ndarray): 真实标签。
        predictions (np.ndarray): 当前模型的预测概率。
        points_x, points_y (np.ndarray): 用于绘制曲面的网格坐标。
        surface_predictions (np.ndarray): 当前模型在网格点上的预测概率。
        dims (int): 预测曲面的网格维度。
    """
    ax0.plot(mse_idx[visible_mse][: idx + 1], errors[visible_mse][: idx + 1], color="red", alpha=0.5)

    # 绘制真实数据点
    ground_truth_legend = ax1.scatter(features[:, 0], features[:, 1], labels, color="red", alpha=0.5, label="Ground Truth")
    # 绘制模型预测点和概率曲面
    predictions_legend = ax1.scatter(features[:, 0], features[:, 1], predictions, color="blue", alpha=0.2, label="Prediction")
    ax1.plot_surface(points_x, points_y, surface_predictions.reshape(dims, dims), color="blue", alpha=0.2)
    ax1.legend((ground_truth_legend, predictions_legend), ("Ground Truth", "Predictions"), loc="upper left")

def fit_logistic(w0, b0, features, labels, dims, epochs, learning_rate, optimizer, output_filename):
    """
    训练 Logistic 回归模型并通过动画可视化训练过程。

    Args:
        w0 (np.ndarray): 初始权重。
        b0 (float): 初始偏置。
        features (np.ndarray): 训练特征。
        labels (np.ndarray): 真实标签。
        dims (int): 可视化中预测曲面的网格维度。
        epochs (int): 训练的总轮数。
        learning_rate (float): 学习率。
        optimizer (function): 用于更新参数的优化器函数。
        output_filename (str): 输出动画的文件名。
    """
    mse_idx = np.arange(1, epochs + 1)
    errors = np.full(epochs, -1)
    ax0, ax1, camera = create_plots_logistic()

    points = np.linspace(0, 1, dims)
    points_x, points_y = np.meshgrid(points, points)
    surface_points = np.column_stack((points_x.flatten(), points_y.flatten()))

    weights = w0
    bias = b0

    for idx in range(epochs):
        error = 0
        predictions = np.array([])
        for x, y in zip(features, labels):
            output = sigmoid(np.dot(weights, x) + bias)
            predictions = np.append(predictions, output)
            error += bce(y, output)
            weights, bias = optimizer(weights, x, bias, y, output, learning_rate)

        # 为了优化动画的生成，我们同样进行非均匀的采样
        if (idx < 5 or (idx < 15 and idx % 5 == 0) or (idx <= 50 and idx % 25 == 0) or (idx <= 1000 and idx % 200 == 0) or idx % 500 == 0):
            surface_predictions = np.array([])
            for surface_point in surface_points:
                output = sigmoid(np.dot(weights, surface_point) + bias)
                surface_predictions = np.append(surface_predictions, output)
            
            print(f"epoch: {idx:>4}, BCE: {round(error, 2)}")
            errors[idx] = error
            visible_mse = errors != -1
            plot_graphs_logistic(ax0, ax1, idx, visible_mse, mse_idx, errors, features, labels, predictions, points_x, points_y, surface_predictions, dims)
            camera.snap()

    animation = camera.animate()
    animation.save(output_filename, writer="pillow")
```

### 3.2.4 训练与可视化

```python
epochs = 5001
learning_rate = 0.0005
dims = 10 # for surface plot

w0 = np.random.rand(X[0].shape[0])
b0 = np.random.rand()

output_filename = "logistic_regression.gif"
fit_logistic(w0, b0, X, Y, dims, epochs, learning_rate, gradient_descent_logistic, output_filename)
```
**训练过程输出:**
```
epoch:    0, BCE: 444.23
epoch:    1, BCE: 438.52
...
epoch: 4500, BCE: 90.24
epoch: 5000, BCE: 89.16
```
![Logistic Regression Animation](../_images/6f922d19a93fcd9f3ee3c76db4fc9245b3d1062a35e05e2a74609cc114c2861d.gif)

动画展示了：
-   **右侧3D图**: 蓝色的预测概率曲面如何从一个随机的初始状态，逐渐“扭曲”和“倾斜”，最终形成一个优美的 S 形曲面，将红色的真实数据点（标签0和1）清晰地分开。模型对每个点的预测概率（蓝色散点）也越来越接近其真实标签。
-   **左侧图**: BCE 损失随着训练的进行而平稳下降，表明模型在不断地学习和优化。

### 3.2.5 交互式 Logistic 回归：探索概率曲面

为了更深刻地理解参数如何影响概率输出，我们可以使用这个交互式沙盘。

![交互式 Logistic 回归](../_images/interactive_logistic_regression.png)

在这个界面中：
-   **滑块**: 你可以手动调整两个特征的权重 `w1`, `w2` 和偏置 `b`。
-   **3D视图**:
    -   **红色/蓝色散点**: 代表了乳腺癌数据集的真实标签（良性/恶性）。
    -   **蓝色曲面**: 这是由你当前参数定义的 Sigmoid 预测概率曲面。曲面的高度代表了模型预测该点为正类（例如“良性”）的概率。

**你的任务**: 尝试调整 `w1`, `w2` 和 `b`，观察蓝色的S形曲面如何变化。你的目标是让这个曲面“恰到好处”地穿过两类数据点之间，使得大部分红色点位于概率接近 0 的区域，而大部分蓝色点位于概率接近 1 的区域。这个过程能让你直观地感受到 Logistic 回归是如何利用一个非线性函数来解决线性不可分问题的。 