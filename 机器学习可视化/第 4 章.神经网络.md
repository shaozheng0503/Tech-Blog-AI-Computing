---
pubDate: 2024-07-26
description: 从零开始构建一个功能完整的前馈神经网络，并与PyTorch实现进行对比。通过函数拟合、XOR分类等案例，深入探索前向传播、反向传播、权重变换、损失景观以及梯度消失等核心概念。
---

# 第 4 章. 神经网络

神经网络是受生物神经系统启发而设计的一类机器学习模型，它通过学习和调整大量的参数（权重和偏置），能够近似极其复杂的函数，在图像识别、自然语言处理等诸多领域取得了革命性的成功。

本章，我们将踏上一段从基础到前沿的旅程。我们首先将完全从零开始，仅使用 `numpy`，以面向对象的方式构建一个功能完备的前馈神经网络。随后，我们会将其与工业级框架 PyTorch 的实现进行对比。最后，我们将深入网络内部，可视化每一层的数据变换、探索权重更新的动态过程，并直面深度学习的一大挑战——梯度消失。

## 4.1 从零开始构建神经网络

我们的第一个任务是构建一个神经网络，让它学习并拟合一个三维空间中的非线性曲面——双曲抛物面。

### 4.1.1 任务设定：拟合双曲抛物面

我们将要拟合的函数是双曲抛物面，其方程为：
$$
z = \frac{y^2}{b^2} - \frac{x^2}{a^2}
$$
这是一个经典的马鞍形曲面。

```python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from celluloid import Camera
import scienceplots
from IPython.display import Image
from abc import ABC, abstractmethod
import copy

np.random.seed(0)
plt.style.use(["science", "no-latex"])

def generate_function(dims):
    """生成双曲抛物面上的数据点"""
    a = 1
    b = 1
    x = np.linspace(-1, 1, dims)
    y = np.linspace(-1, 1, dims)
    X, Y = np.meshgrid(x, y)
    Z = (Y**2 / b**2) - (X**2 / a**2)

    features = np.stack((X.flatten(), Y.flatten()), axis=1)
    # Reshape for the network (batch_size, features_in, 1) -> (n_samples, 2, 1)
    features = features.reshape((features.shape[0], features.shape[1], 1))
    labels = Z.flatten().reshape((len(Z.flatten()), 1, 1))

    return X, Y, Z, features, labels

dims = 12
X, Y, Z, features, labels = generate_function(dims)

# 可视化目标函数
fig = plt.figure()
ax = fig.add_subplot(111, projection="3d")
ax.plot_surface(X, Y, Z, color="red", alpha=0.5)
ax.set_title("Hyperbolic Paraboloid (Ground Truth)")
plt.show()
```

### 4.1.2 核心理论

#### 损失函数：均方误差 (MSE)
对于回归任务，均方误差（Mean Squared Error）是一个常用的损失函数，它衡量了模型预测值与真实值之间差异的平方的平均值。
$$
L = \frac{1}{n} \sum_{i=1}^{n} (y_{\text{true}}^{(i)} - y_{\text{pred}}^{(i)})^2
$$
其梯度为：
$$
\frac{\partial L}{\partial y_{\text{pred}}} = \frac{2}{n} (y_{\text{pred}} - y_{\text{true}})
$$

```python
def mse(y_true, y_pred):
    return np.mean(np.power(y_true - y_pred, 2))

def mse_prime(y_true, y_pred):
    return 2 * (y_pred - y_true) / np.size(y_true)
```

#### 模块化构建：层 (Layer)
一个神经网络由许多“层”堆叠而成。为了代码的整洁和可复用性，我们首先定义一个抽象基类 `Layer`，它规定了所有类型的层都必须具备 `forward`（前向传播）和 `backward`（反向传播）两个核心方法。

```python
class Layer(ABC):
    def __init__(self):
        self.input = None
        self.output = None

    @abstractmethod
    def forward(self, input_data):
        pass

    @abstractmethod
    def backward(self, output_gradient, optimizer):
        pass
```

#### 前向传播 (Forward Propagation)
前向传播是将输入数据通过网络，逐层计算，最终得到预测值的过程。对于一个全连接层（`Dense`层），其核心操作是一个线性变换，即输入向量与权重矩阵相乘，再加上一个偏置向量。
$$
\text{output} = \text{activation}(W \cdot \text{input} + B)
$$
其中，$W$ 是该层的权重矩阵，$B$ 是偏置向量，`input` 是来自上一层的输出数据，`activation` 是非线性激活函数。我们将构建一个三层的全连接网络，每层之后都使用 Tanh 激活函数。

#### 反向传播 (Backpropagation)
反向传播是神经网络学习的精髓。它使用链式法则，从最后一层开始，逐层计算损失函数对每一层参数（权重和偏置）的梯度，然后使用梯度下降来更新这些参数。

我们的目标是使用梯度下降更新规则：
$$
W_{\text{new}} = W_{\text{old}} - \eta \frac{\partial L}{\partial W} \\
B_{\text{new}} = B_{\text{old}} - \eta \frac{\partial L}{\partial B}
$$
这里的关键是计算梯度 $\frac{\partial L}{\partial W}$ 和 $\frac{\partial L}{\partial B}$。根据链式法则，对于任意一层，其权重的梯度可以分解为：
$$
\frac{\partial L}{\partial W} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z} \cdot \frac{\partial z}{\partial W}
$$
其中，$L$ 是总损失，$\hat{y}$ 是该层的输出（激活后的值），$z$ 是该层的线性输出（激活前的值）。让我们分解这三项：
1.  $\frac{\partial L}{\partial \hat{y}}$: 这是总损失对该层输出的梯度。对于最后一层，它就是损失函数本身的梯度。对于隐藏层，这个值是从下一层反向传播过来的梯度。
2.  $\frac{\partial \hat{y}}{\partial z}$: 这是激活函数对输入的导数。
3.  $\frac{\partial z}{\partial W}$: 这是线性输出对权重的导数，它恰好等于该层的输入 `input`。

将它们组合起来，我们得到权重和偏置的梯度计算公式：
-   **权重梯度**: $(\text{下一层传来的梯度}) \otimes (\text{激活函数的梯度}) \cdot (\text{本层的输入})^T$
-   **偏置梯度**: $(\text{下一层传来的梯度}) \otimes (\text{激活函数的梯度})$

(注：$\otimes$ 表示逐元素相乘)

### 4.1.3 代码实现

#### 全连接层 (Dense Layer)
`Dense` 层实现了上述的线性变换和反向传播逻辑。我们使用 Xavier 初始化（一种让信号在网络中更稳定传播的策略）来设置初始权重。这种方法通过精心设计权重的初始方差，确保了在前向和反向传播过程中，信号的方差保持大致恒定，从而有效避免了梯度消失或爆炸的问题。

```python
class Dense(Layer):
    def __init__(self, input_neurons, output_neurons):
        # Xavier 初始化 (Uniform)
        limit = np.sqrt(6 / (input_neurons + output_neurons))
        self.weights = np.random.uniform(-limit, limit, size=(output_neurons, input_neurons))
        self.bias = np.zeros((output_neurons, 1))

    def forward(self, input_data):
        self.input = input_data
        return np.matmul(self.weights, self.input) + self.bias

    def backward(self, output_gradient, optimizer):
        weights_gradient = np.matmul(output_gradient, self.input.T)
        input_gradient = np.dot(self.weights.T, output_gradient)

        # 使用优化器更新参数
        self.weights, self.bias = optimizer.backward(
            self.weights, weights_gradient, self.bias, output_gradient
        )
        return input_gradient
```

#### 激活层 (Activation Layer)
`Activation` 层将一个给定的激活函数及其导数应用于输入数据。它的反向传播非常简单，就是将上游传来的梯度与激活函数的局部梯度（导数）进行逐元素相乘。

```python
class Activation(Layer):
    def __init__(self, activation, activation_prime):
        self.activation = activation
        self.activation_prime = activation_prime

    def forward(self, input_data):
        self.input = input_data
        return self.activation(self.input)

    def backward(self, output_gradient, optimizer):
        return np.multiply(output_gradient, self.activation_prime(self.input))
```

#### Tanh 激活函数
我们选择 Tanh 作为激活函数。其函数及导数如下：
$$
\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \\
\tanh'(x) = 1 - \tanh^2(x)
$$

```python
class Tanh(Activation):
    def __init__(self):
        tanh = lambda x: np.tanh(x)
        tanh_prime = lambda x: 1 - np.tanh(x) ** 2
        super().__init__(tanh, tanh_prime)
```

#### 优化器 (Optimizer)
优化器负责根据计算出的梯度来更新模型的参数。我们实现一个简单的随机梯度下降（SGD）优化器。

```python
class GradientDescentOptimizer:
    def __init__(self, learning_rate):
        self.learning_rate = learning_rate

    def backward(self, weights, weights_gradient, bias, bias_gradient):
        weights -= self.learning_rate * weights_gradient
        bias -= self.learning_rate * bias_gradient
        return weights, bias
```

### 4.1.4 训练与可视化

我们将训练过程封装在一个 `fit` 函数中，它会迭代数据、执行前向和反向传播，并调用绘图函数生成动画。

<details>
<summary>点击展开/折叠：附录 A - 从零实现所需的可视化辅助函数</summary>

```python
def create_scatter_and_3d_plot():
    fig, ax = plt.subplots(1, 3, figsize=(16 / 9.0 * 4, 4 * 1))
    fig.suptitle("Neural Network Predictions")

    ax[0].set_xlabel("Epoch", fontweight="normal")
    ax[0].set_ylabel("Error", fontweight="normal")
    ax[0].set_title("Mean Squared Error")

    ax[1].axis("off")
    ax[2].axis("off")

    ax[2] = fig.add_subplot(1, 2, 2, projection="3d")
    ax[2].set_xlabel("X")
    ax[2].set_ylabel("Y")
    ax[2].set_zlabel("Z")
    ax[2].set_title("Function Approximation")
    ax[2].view_init(20, -35)
    ax[2].set_zlim(-1, 1)
    ax[2].axis("equal")

    camera = Camera(fig)
    return ax[0], ax[2], camera


def create_3d_and_3d_plot():
    fig, ax = plt.subplots(
        1, 2, figsize=(16 / 9.0 * 4, 4 * 1), subplot_kw={"projection": "3d"}
    )
    fig.suptitle("Neural Network Loss Landscape")

    ax[0].set_xlabel("W3_1")
    ax[0].set_ylabel("W3_2")
    ax[0].set_zlabel("MSE")
    ax[0].set_title("Mean Squared Error")
    ax[0].view_init(20, -35)
    ax[0].set_zlim(-1, 1)
    ax[0].axis("equal")

    ax[1].set_xlabel("X")
    ax[1].set_ylabel("Y")
    ax[1].set_zlabel("Z")
    ax[1].set_title("Function Approximation")
    ax[1].view_init(20, -35)
    ax[1].set_zlim(-1, 1)
    ax[1].axis("equal")

    camera = Camera(fig)
    return ax[0], ax[1], camera


def plot_3d_predictions(ax, X, Y, Z, predictions, dims):
    # Plot Neural Network Function Approximation
    # Ground truth
    ground_truth_legend = ax.plot_surface(
        X, Y, Z, color="red", alpha=0.5, label="Ground Truth"
    )

    # Neural Network Predictions
    predictions_legend = ax.scatter(
        X,
        Y,
        predictions.reshape((dims, dims)),
        color="blue",
        alpha=0.2,
        label="Prediction",
    )
    ax.plot_surface(
        X,
        Y,
        predictions.reshape((dims, dims)),
        color="blue",
        alpha=0.3,
    )
    ax.legend(
        (ground_truth_legend, predictions_legend),
        ("Ground Truth", "Predictions"),
        loc="upper left",
    )


def plot_layer_loss_landscape(
    ax0,
    network,
    target_layer_idx,
    features,
    labels,
    w1_min,
    w1_max,
    w2_min,
    w2_max,
    loss_dims,
):
    # current target layer weights
    target_layer_idx = target_layer_idx % len(network)

    w1 = network[target_layer_idx].weights[0][0]
    w2 = network[target_layer_idx].weights[0][1]
    curr_error = 0
    for x, y in zip(features, labels):
        output = x
        for layer in network:
            output = layer.forward(output)

        curr_error += mse(y, output)
    curr_error /= labels.size
    ax0.scatter([w1], [w2], [curr_error], color="red", alpha=0.4)

    target_layer = copy.deepcopy(network[target_layer_idx])
    w1_range = np.linspace(w1_min, w1_max, loss_dims)
    w2_range = np.linspace(w2_min, w2_max, loss_dims)
    w1_range, w2_range = np.meshgrid(w1_range, w2_range)
    w_range = np.stack((w1_range.flatten(), w2_range.flatten()), axis=1)

    error_range = np.array([])

    for target_layer_weight in w_range:
        target_layer_weight = target_layer_weight.reshape(1, 2)
        target_layer.weights[0, :2] = target_layer_weight[0, :2]

        error = 0
        for x, y in zip(features, labels):
            output = x
            for layer_idx, layer in enumerate(network):
                if layer_idx == target_layer_idx:
                    output = target_layer.forward(output)
                else:
                    output = layer.forward(output)

            error += mse(y, output)
        error /= labels.size
        error_range = np.append(error_range, error)

    ax0.plot_surface(
        w1_range,
        w2_range,
        error_range.reshape(loss_dims, loss_dims),
        color="blue",
        alpha=0.1,
    )


def plot_mse_and_predictions(
    ax0, ax1, idx, visible_mse, mse_idx, errors, X, Y, Z, predictions, dims
):
    ax0.plot(
        mse_idx[visible_mse][: idx + 1],
        errors[visible_mse][: idx + 1],
        color="red",
        alpha=0.5,
    )

    plot_3d_predictions(ax1, X, Y, Z, predictions, dims)


def plot_loss_landscape_and_predictions(
    ax0,
    ax1,
    network,
    target_layer_idx,
    features,
    labels,
    X,
    Y,
    Z,
    predictions,
    preds_dims,
    w1_min=-5,
    w1_max=5,
    w2_min=-5,
    w2_max=5,
    loss_dims=20,
):
    plot_3d_predictions(ax1, X, Y, Z, predictions, preds_dims)
    plot_layer_loss_landscape(
        ax0,
        network,
        target_layer_idx,
        features,
        labels,
        w1_min,
        w1_max,
        w2_min,
        w2_max,
        loss_dims,
    )


def show_epoch(epoch):
    return (
        epoch < 25
        or (epoch < 25 and epoch % 2 == 0)
        or (epoch <= 100 and epoch % 10 == 0)
        or (epoch <= 500 and epoch % 25 == 0)
        or (epoch <= 1000 and epoch % 50 == 0)
        or epoch % 250 == 0
    )
```
</details>

```python
def fit(network, features, labels, X, Y, Z, preds_dims, epochs, optimizer, mse_plot_filename, loss_landscape_plot_filename):
    mse_idx = np.arange(1, epochs + 1)
    errors = np.full(epochs, -1)
    mse_ax, predictions_ax1, camera1 = create_scatter_and_3d_plot()
    loss_landscape_ax, predictions_ax2, camera2 = create_3d_and_3d_plot()

    for idx in range(epochs):
        error = 0
        predictions = np.array([])
        for x, y in zip(features, labels):
            # 前向传播
            output = x
            for layer in network:
                output = layer.forward(output)
            predictions = np.append(predictions, output)
            
            # 计算损失
            error += mse(y, output)

            # 反向传播
            grad = mse_prime(y, output)
            for layer in reversed(network):
                grad = layer.backward(grad, optimizer)

        error /= len(features)
        
        # 可视化部分
        if show_epoch(idx): # show_epoch 是一个辅助函数，用于控制绘图频率
            print(f"epoch: {idx}, MSE: {error}")

            # Plot MSE
            errors[idx] = error
            visible_mse = errors != -1
            plot_mse_and_predictions(
                mse_ax,
                predictions_ax1,
                idx,
                visible_mse,
                mse_idx,
                errors,
                X,
                Y,
                Z,
                predictions,
                preds_dims,
            )

            # plot the loss landscape of the second to last layer
            # a 3D plot can be made because it's only 2 neurons
            plot_loss_landscape_and_predictions(
                loss_landscape_ax,
                predictions_ax2,
                network,
                -2,
                features,
                labels,
                X,
                Y,
                Z,
                predictions,
                preds_dims,
            )
            camera1.snap()
            camera2.snap()

    animation1 = camera1.animate()
    animation1.save(mse_plot_filename, writer="pillow")
    animation2 = camera2.animate()
    animation2.save(loss_landscape_plot_filename, writer="pillow")
    plt.show()

# 定义模型结构
model = [Dense(2, 12), Tanh(), Dense(12, 2), Tanh(), Dense(2, 1), Tanh()]

# 定义优化器和超参数
epochs = 301
learning_rate = 0.005
optimizer = GradientDescentOptimizer(learning_rate)

# 启动训练
fit(model, features, labels, X, Y, Z, dims, epochs, optimizer, "neural_network.gif", "neural_network_loss_landscape.gif")
```
**训练过程输出:**
```
epoch: 0, MSE: 3.0033681391919607
...
epoch: 300, MSE: 0.16213374967702018
```

#### 结果分析
![函数拟合过程](../_images/6aa17f9a521c2910de2c6de26981e5c772f951813f5258848a1262cd3c41830f.gif)
上图展示了函数拟合的全过程。左侧是均方误差（MSE）随训练轮数的变化，右侧是3D视图。可以看到：
-   **MSE曲线**: 损失从一个较高的初始值迅速下降，表明模型在快速学习。
-   **3D视图**: 蓝色的预测点云（代表神经网络的输出）从一个无序的初始状态，逐渐变形、伸展，最终与红色的真实曲面（双曲抛物面）完美地贴合在一起。这生动地证明了我们的神经网络成功地学习到了这个非线性函数的内在模式。

![损失景观](../_images/2416150f78cd542011a8cc27f22f01706cb7b5b70c55a8bc1a45fa7fb5f2e735.gif)
上图则提供了另一个独特的视角——**损失景观 (Loss Landscape)**。
-   **左侧3D图**: 展示了倒数第二层的两个权重与总损失（MSE）之间的关系。红点代表该层权重在当前训练轮数下的取值。可以看到，随着训练的进行，红点沿着蓝色的损失曲面“滚落”，最终稳定在“山谷”的最低点。这正是梯度下降算法在寻找最优解的可视化体现。

## 4.2 使用 PyTorch 实现
从零构建神经网络有助于我们理解其底层原理，但在实际工程中，我们会使用 PyTorch、TensorFlow 这样的深度学习框架。它们提供了高度优化、可自动求导的模块，极大地简化了开发流程。

下面，我们用 PyTorch 来实现完全相同的网络。

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class TorchNet(nn.Module):
    def __init__(self):
        super(TorchNet, self).__init__()
        self.fc1 = nn.Linear(2, 12)
        self.fc2 = nn.Linear(12, 2)
        self.fc3 = nn.Linear(2, 1)

    def forward(self, x):
        x = torch.tanh(self.fc1(x))
        x = torch.tanh(self.fc2(x))
        return torch.tanh(self.fc3(x))

def torch_fit(model, features, labels, X, Y, Z, dims, epochs, optimizer, output_filename):
    mse_idx = np.arange(1, epochs + 1)
    errors = np.full(epochs, -1)
    # create_scatter_and_3d_plot 和 show_epoch 在附录A中定义
    mse_ax, predictions_ax1, camera1 = create_scatter_and_3d_plot()

    loss_fn = nn.MSELoss()

    for idx in range(epochs):
        error = 0
        predictions = np.array([])

        # 为保持与从零实现一致，我们逐一样本迭代，尽管PyTorch支持批处理
        for x, y in zip(features, labels):
            # 前向传播
            output = model(x)
            output_np = output.detach().cpu().numpy()
            predictions = np.append(predictions, output_np)

            # 计算损失
            loss = loss_fn(output, y)
            error += loss.detach().cpu().numpy()

            # 反向传播
            optimizer.zero_grad() # 清空过往梯度，因PyTorch默认会累积梯度
            loss.backward()       # 自动计算当前loss的梯度
            optimizer.step()      # 根据梯度更新权重

        error /= len(X)

        if show_epoch(idx):
            print(f"epoch: {idx}, MSE: {error}")

            # 绘制MSE和预测
            errors[idx] = error
            visible_mse = errors != -1
            plot_mse_and_predictions(
                mse_ax,
                predictions_ax1,
                idx,
                visible_mse,
                mse_idx,
                errors,
                X,
                Y,
                Z,
                predictions,
                dims,
            )

            camera1.snap()

    animation1 = camera1.animate()
    animation1.save(output_filename, writer="pillow")
    plt.show()

# 准备数据 (转换为 PyTorch Tensors)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
torch_model = TorchNet().to(device)
# squeeze(2) 是因为我们的 from-scratch 版本接受 (n, 2, 1) 的输入, PyTorch nn.Linear 接受 (n, 2)
features_tensor = torch.tensor(features, device=device, dtype=torch.float32).squeeze(2)
labels_tensor = torch.tensor(labels, device=device, dtype=torch.float32).squeeze(2)

# 定义损失函数和优化器
epochs = 101 # 使用更少的epochs，因为PyTorch通常收敛更快
learning_rate = 0.005
optimizer = torch.optim.SGD(torch_model.parameters(), lr=learning_rate)

# 执行训练
output_filename_pytorch = "neural_network_pytorch.gif"
torch_fit(
    torch_model,
    features_tensor,
    labels_tensor,
    X,
    Y,
    Z,
    dims,
    epochs,
    optimizer,
    output_filename_pytorch,
)
```
![PyTorch 实现结果](../_images/91b735ffd399affd256bd159d10083d96f56e0b16dc35516d975541b107aef4d.gif)
可以看到，PyTorch 的实现代码量大大减少，且无需我们手动实现反向传播的复杂逻辑。最终的拟合效果与我们从零开始的实现同样出色，验证了我们自己构建的网络的正确性。

## 4.3 深入探索：权重、变换与梯度

现在，让我们利用 PyTorch 的便利性，去探索一些更深层次的问题。

### 4.3.1 任务设定：解决 XOR 问题
异或（XOR）问题是机器学习中的一个经典案例。XOR 数据集是线性不可分的，任何单一的直线（或平面）都无法将其完美分割。这正是检验神经网络非线性能力的绝佳“试金石”。

```python
def generate_XOR():
    N = 500
    X = np.random.rand(N, 2)
    y = (X[:, 0] > 0.5) != (X[:, 1] > 0.5)
    return X, y

X_xor, y_xor = generate_XOR()

plt.figure()
plt.scatter(X_xor[:, 0], X_xor[:, 1], c=y_xor, alpha=0.5)
plt.title("XOR Dataset (Linearly Inseparable)")
plt.show()
```
![XOR Dataset](../_images/99408a1f23f40e3c68e8957b39a11e7cbef92e3660097cb067ea4e727409a01a.png)

### 4.3.2 可视化每一层的线性变换
神经网络之所以能解决非线性问题，关键在于它通过一层又一层的**线性变换 + 非线性激活**，将原始数据从一个特征空间投影到另一个特征空间，直到在某个高维空间中，数据变得线性可分。

我们构建一个特殊的 `VisualNet`，来捕捉并可视化每一层处理后的数据形态。

<details>
<summary>点击展开/折叠：附录 B - 高级可视化所需代码</summary>

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

def create_scatterplots(rows=2, cols=3, width_scale=1, height_scale=1):
    fig, axes = plt.subplots(
        rows,
        cols,
        figsize=(16 / 9.0 * 4 * width_scale, 4 * height_scale),
        layout="constrained",
    )
    axes = axes.flatten()

    layer_idx = 0
    for i, axis in enumerate(axes):
        if not ((i + 1) % cols == 0):
            axis.set_title(f"Layer {layer_idx}")
            layer_idx += 1

    axes[-1].set_title("Predictions")
    axes[-1 - cols].set_title("Mean Squared Error")

    camera = Camera(fig)
    return axes, camera


def create_3d_plots(rows=2, cols=3, width_scale=1, height_scale=1):
    fig = plt.figure(
        figsize=(16 / 9.0 * 4 * width_scale, 4 * height_scale), layout="constrained"
    )
    axes = []

    layer_idx = 0
    for i in range(rows * cols):
        if not ((i + 1) % cols == 0):
            axis = fig.add_subplot(rows, cols, i + 1, projection="3d")
            axis.set_title(f"Layer {layer_idx + 1}")
            axes.append(axis)
            layer_idx += 1
        else:
            axes.append(fig.add_subplot(rows, cols, i + 1))

    axes[-1].set_title("Predictions")
    axes[-1 - cols].set_title("Mean Squared Error")

    camera = Camera(fig)
    return axes, camera


def plot_layer_loss_landscape_torch(
    axis,
    model,
    target_layer_idx,
    neuron_idx,
    features,
    labels,
    w1_min,
    w1_max,
    w2_min,
    w2_max,
    loss_dims,
    device,
    color="blue",
):
    """Plot how the loss changes when the first two weights in the first neuron change"""
    loss_fn = nn.MSELoss()

    init = model.get_values(target_layer_idx, neuron_idx)
    w1 = init[0].item()
    w2 = init[1].item()

    target_layer_idx = target_layer_idx % len(model.layers)

    w1_range = torch.linspace(w1_min + w1, w1_max + w1, loss_dims).to(device)
    w2_range = torch.linspace(w2_min + w2, w2_max + w2, loss_dims).to(device)
    w1_range, w2_range = torch.meshgrid(w1_range, w2_range, indexing="ij")
    w_range = torch.stack((w1_range.flatten(), w2_range.flatten()), axis=1)

    error_range = np.array([])

    for target_layer_weight in w_range:
        model.override_layer_weight(
            target_layer_idx, neuron_idx, init + target_layer_weight
        )
        error = 0
        for x, y in zip(features, labels):
            output = model(x)
            y = y.unsqueeze(0)
            loss = loss_fn(output, y)
            error += loss.detach().cpu().numpy()
        error /= len(labels)
        error_range = np.append(error_range, error)

        if np.isclose(target_layer_weight[0].item(), w1, atol=0.25) and np.isclose(
            target_layer_weight[1].item(), w2, atol=0.25
        ):
            axis.scatter([w1], [w2], [error], color=color, alpha=0.4)

    axis.plot_surface(
        w1_range.detach().cpu().numpy(),
        w2_range.detach().cpu().numpy(),
        error_range.reshape(loss_dims, loss_dims),
        color=color,
        alpha=0.1,
    )
    model.override_layer_weight(target_layer_idx, neuron_idx, init)


def plot_mse_and_predictions_torch(
    axes, features, idx, visible_mse, mse_idx, errors, predictions, cmap, cols, device
):
    features_cpu = features.detach().cpu().numpy()

    # Plot MSE
    mse_ax = axes[-1 - cols]
    mse_ax.plot(
        mse_idx[visible_mse][: idx + 1],
        errors[visible_mse][: idx + 1],
        color="red",
        alpha=0.5,
    )
    mse_ax.plot(
        [1],
        [0],
        color="white",
        alpha=0,
    )

    # Plot Predictions
    predictions_classes = np.where(predictions > 0.5, 1, 0)

    predictions_ax = axes[-1]
    predictions_ax.scatter(
        features_cpu[:, 0],
        features_cpu[:, 1],
        c=predictions_classes,
        cmap=cmap,
        alpha=0.5,
    )


def plot_transformations_and_predictions(
    axes,
    model,
    idx,
    visible_mse,
    mse_idx,
    errors,
    predictions,
    features,
    labels,
    cmap,
    rows,
    cols,
    device,
):
    plot_mse_and_predictions_torch(
        axes,
        features,
        idx,
        visible_mse,
        mse_idx,
        errors,
        predictions,
        cmap,
        cols,
        device,
    )
    model.visualize(features, labels, axes, cmap, rows, cols)


def plot_loss_landscape_and_predictions_torch(
    axes,
    model,
    idx,
    visible_mse,
    mse_idx,
    errors,
    predictions,
    features,
    labels,
    cmap,
    cols,
    device,
    w1_min=-5,
    w1_max=5,
    w2_min=-5,
    w2_max=5,
    loss_dims=7,
):
    # this uses axes with index -1 and -1-cols
    plot_mse_and_predictions_torch(
        axes,
        features,
        idx,
        visible_mse,
        mse_idx,
        errors,
        predictions,
        cmap,
        cols,
        device,
    )

    num_layers = len(model.layers)
    target_layer_idx = -1

    for index, axis in enumerate(reversed(axes)):
        # in reverse order, predictions plot is index 0 and mse plot is index cols
        if index == 0 or index == cols or abs(target_layer_idx) > num_layers:
            continue
        plot_layer_loss_landscape_torch(
            axis,
            model,
            target_layer_idx,
            0,
            features,
            labels,
            w1_min,
            w1_max,
            w2_min,
            w2_max,
            loss_dims,
            device,
            color="blue",
        )
        if target_layer_idx != -1:
            plot_layer_loss_landscape_torch(
                axis,
                model,
                target_layer_idx,
                1,
                features,
                labels,
                w1_min,
                w1_max,
                w2_min,
                w2_max,
                loss_dims,
                device,
                color="red",
            )
        target_layer_idx -= 1

class VisualNet(nn.Module):
    def __init__(self):
        super(VisualNet, self).__init__()
        self.layers = nn.ModuleList()

    def visualize(self, X, y, axes, cmap, rows, cols):
        y_cpu = y.detach().cpu().numpy()

        layer_idx = 0
        for i, axis in enumerate(axes):
            if not ((i + 1) % cols == 0):
                X_cpu = X.detach().cpu().numpy()

                # input and hidden layer outputs
                if X.shape[1] != 1:
                    axis.scatter(
                        X_cpu[:, 0], X_cpu[:, 1], c=y_cpu, cmap=cmap, alpha=0.5
                    )
                # output layer is 1D, so set second dimenstional to zeros
                else:
                    axis.scatter(
                        X_cpu[:, 0],
                        np.zeros(X_cpu[:, 0].shape),
                        c=y_cpu,
                        cmap=cmap,
                        alpha=0.5,
                    )

                if layer_idx < len(self.layers):
                    X = torch.tanh(self.layers[layer_idx](X))
                    layer_idx += 1

    def override_layer_weight(self, layer_idx, neuron_idx, new_weights):
        if (abs(layer_idx) > len(self.layers)) or (
            abs(neuron_idx) > len(self.layers[layer_idx].weight)
        ):
            return

        with torch.no_grad():
            self.layers[layer_idx].weight[neuron_idx, :2] = new_weights

    def get_values(self, layer_idx, neuron_idx):
        if (abs(layer_idx) > len(self.layers)) or (
            abs(neuron_idx) > len(self.layers[layer_idx].weight)
        ):
            return torch.zeros(2)

        with torch.no_grad():
            return self.layers[layer_idx].weight.detach().clone()[neuron_idx, :2]


class VisualTorchNet(VisualNet):
    def __init__(self, num_hidden_layers):
        super().__init__()

        # define the layers
        self.input_layer = nn.Linear(2, 2)
        self.layers.append(self.input_layer)

        for i in range(num_hidden_layers):
            self.layers.append(nn.Linear(2, 2))

        self.output_layer = nn.Linear(2, 1)
        self.layers.append(self.output_layer)

    def forward(self, x):
        # pass the result of the previous layer to the next layer
        for layer in self.layers[:-1]:
            x = torch.tanh(layer(x))

        return self.output_layer(x)

def advanced_torch_fit(
    model,
    features,
    labels,
    epochs,
    learning_rate,
    transformations_plot_filename,
    loss_landscape_plot_filename,
    device,
    rows=2,
    cols=3,
    width_scale=1,
    height_scale=1,
):
    mse_idx = np.arange(1, epochs + 1)
    errors = np.full(epochs, -1)

    cmap = plt.cm.colors.ListedColormap(["red", "blue"])

    scatterplots, camera1 = create_scatterplots(rows, cols, width_scale, height_scale)
    loss_plots, camera2 = create_3d_plots(rows, cols, width_scale, height_scale)

    loss_fn = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.3)

    for idx in range(epochs):
        error = 0
        predictions = np.array([])

        for x, y in zip(features, labels):
            # Forward Propagation
            output = model(x)

            output_np = output.detach().cpu().numpy()
            predictions = np.append(predictions, output_np)

            # Store Error
            y = y.unsqueeze(0)
            loss = loss_fn(output, y)

            error += loss.detach().cpu().numpy()

            # Backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        if (
            idx < 5
            or (idx <= 50 and idx % 5 == 0)
            or (idx <= 1000 and idx % 50 == 0)
            or idx % 250 == 0
        ):
            print(f"epoch: {idx}, MSE: {error}")

            errors[idx] = error
            visible_mse = errors != -1

            plot_transformations_and_predictions(
                scatterplots,
                model,
                idx,
                visible_mse,
                mse_idx,
                errors,
                predictions,
                features,
                labels,
                cmap,
                rows,
                cols,
                device,
            )

            plot_loss_landscape_and_predictions_torch(
                loss_plots,
                model,
                idx,
                visible_mse,
                mse_idx,
                errors,
                predictions,
                features,
                labels,
                cmap,
                cols,
                device,
            )

            camera1.snap()
            camera2.snap()

    animation1 = camera1.animate()
    animation1.save(transformations_plot_filename, writer="pillow")
    animation2 = camera2.animate()
    animation2.save(loss_landscape_plot_filename, writer="pillow")

    plt.show()
```
</details>

```python
# 为XOR问题实例化并训练网络
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# 我们使用一个包含2个隐藏层的网络来解决XOR问题
xor_model = VisualTorchNet(num_hidden_layers=2).to(device)

X_tensor = torch.tensor(X_xor, device=device, dtype=torch.float32)
y_tensor = torch.tensor(y_xor, device=device, dtype=torch.float32)

# 执行训练 (使用附录B中的 advanced_torch_fit)
advanced_torch_fit(
    model=xor_model,
    features=X_tensor,
    labels=y_tensor,
    epochs=601,
    learning_rate=0.005,
    transformations_plot_filename="neural_network_weights.gif",
    loss_landscape_plot_filename="neural_network_weights_loss_landscape.gif",
    device=device,
    rows=2,
    cols=3,
)
```

![层级变换过程](../_images/7c5e7330879b8f16dc809174dfd753092a9b6bb249f9c4b23f0b23bef10a3ef4.gif)
上图动画的每一帧展示了神经网络中数据流动的完整快照：
-   **前几列**: 显示了数据（红点和蓝点）经过每一层后的样子。可以看到，原始的 XOR 数据在第一层之后就被拉伸和扭曲，到了第三层，原本混杂在一起的红蓝点已经被清晰地分到了两侧，变得线性可分。
-   **最后一列**: 是模型最终的分类预测结果。
这个可视化生动地揭示了深度学习的“黑箱”：它通过逐层变换，将复杂问题简化为简单问题。

### 4.3.3 挑战：梯度消失问题 (Vanishing Gradients)
一个自然的想法是：网络越深，能力越强。但实践并非如此简单。当网络层数过多时，可能会遇到**梯度消失**问题。这是因为在反向传播过程中，梯度需要通过链式法则逐层相乘。如果激活函数的导数持续小于1（例如 Tanh 在其饱和区），那么梯度在传过多层后会迅速衰减成一个极小的值，导致靠近输入层的网络权重几乎无法更新，网络也就“学不动”了。

我们构建一个 12 层的深层网络来复现这个问题。

```python
# 构建一个12层(1个输入层+10个隐藏层+1个输出层)的网络
deep_model = VisualTorchNet(num_hidden_layers=10).to(device)

# 使用相同的XOR数据进行训练
advanced_torch_fit(
    model=deep_model,
    features=X_tensor,
    labels=y_tensor,
    epochs=1001,
    learning_rate=0.005,
    transformations_plot_filename="vanishing_gradients/layers_12.gif",
    loss_landscape_plot_filename="vanishing_gradients/layers_12_loss_landscape.gif",
    device=device,
    rows=2,
    cols=7,
    width_scale=4,
    height_scale=2,
)
```
![梯度消失现象](../_images/351929eaeb6e41c9d8ff8d329d7b8a5fd834f48f2a2e47f213fd18c6ae0a337e.gif)
观察上图，这是一个 12 层网络的训练过程。注意看前几列的子图，代表了网络中靠近输入的前几层。在整个训练过程中，这些子图中的数据点几乎没有任何变化。这表明这些层的权重没有得到有效更新，梯度在反向传播到它们那里时已经消失了。相比之下，后面几层（靠右的子图）则有明显的变化。

这个问题极大地限制了早期深层网络的训练。后续的研究，如 ResNet 中提出的“残差连接”，正是为了解决梯度消失/爆炸问题，从而使得训练成百上千层的超深网络成为可能。我们将在后续章节中继续探讨这些先进的架构。 